{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run auxTensor.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generating TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating a new dataframe without containing the last release...\n",
      "... DONE!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountClassCoupled</th>\n",
       "      <th>CountDeclMethod</th>\n",
       "      <th>CountDeclMethodAll</th>\n",
       "      <th>CountClassDerived</th>\n",
       "      <th>CountLineCode</th>\n",
       "      <th>SumCyclomatic</th>\n",
       "      <th>PercentLackOfCohesion</th>\n",
       "      <th>MaxInheritanceTree</th>\n",
       "      <th>Path</th>\n",
       "      <th>will_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>77</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>com.oreilly.servlet.MailMessage.MailMessage.java</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>15</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>com.oreilly.servlet.MailPrintStream.MailMessag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.tools.ant.AllJUnitTests.AllJUnitTes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>88</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.tools.ant.BuildEvent.BuildEvent.java</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>29</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.tools.ant.BuildException.BuildExcep...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>26</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.DefaultLogger.DefaultLogg...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.DesirableFilter.Desirable...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>74</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.DirectoryScanner.Director...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>88</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.EnumeratedAttribute.Enume...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>10</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.tools.ant.EnumeratedAttributeTest.E...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.tools.ant.EnumeratedAttributeTest.T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.tools.ant.EnumeratedAttributeTest.T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>24</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.IntrospectionHelper.Intro...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.IntrospectionHelper.Intro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.IntrospectionHelper.Intro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.IntrospectionHelper.creat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.IntrospectionHelper.creat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.IntrospectionHelper.creat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.IntrospectionHelper.creat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.IntrospectionHelper.creat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.IntrospectionHelper.creat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.IntrospectionHelper.creat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.IntrospectionHelper.creat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.IntrospectionHelper.creat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.IntrospectionHelper.creat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.IntrospectionHelper.creat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.IntrospectionHelper.creat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.IntrospectionHelper.creat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.apache.tools.ant.IntrospectionHelperTest.I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>61</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.apache.tools.ant.Location.Location.java</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8980</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.example.junit.AbstractJUnit3TestNotMissed....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8981</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>org.example.junit.AbstractJUnit3TestNotMissed....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8982</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.example.junit.AbstractTestMissed.AbstractT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8983</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.example.junit.AbstractTestNotMissed.Abstra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8984</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.example.junit.AbstractTestNotMissed.InnerA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8985</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.example.junit.JUnit3NonTestMissed.JUnit3No...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8986</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.example.junit.JUnit3TestNotMissed.JUnit3Te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8987</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.example.junit.JUnit4Skippable.JUnit4Skippa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.example.junit.MultilineAsserts.MultilineAs...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8989</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.example.junit.NonTestMissed.NonTestMissed....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8990</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.example.junit.Output.Output.java</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8991</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.example.junit.TestNotMissed.TestNotMissed....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8992</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.example.junit.TestWithSuiteNotMissed.TestW...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8993</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.example.junit.ThreadedOutput.ThreadedOutpu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8994</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.example.junit.ThreadedOutput.testOutput.(A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.example.junit.Timeout.Timeout.java</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.example.junit.XmlParserTest.XmlParserTest....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>org.example.tasks.TaskdefTestContainerTask.Tas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>org.example.tasks.TaskdefTestSimpleTask.Taskde...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>org.example.tasks.TaskdefTestSimpleTask.Echo.T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>org.example.types.TypedefTestType.TypedefTestT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9001</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>task.BaseTask.BaseTask.java</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9002</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>task.EchoLocation.EchoLocation.java</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>task.UUDecodeTask.UUDecodeTask.java</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9004</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>task.UUEncodeTask.UUEncodeTask.java</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9005</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test.ContainsOnlyInner.ContainsOnlyInner.java</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9006</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test.MethodParam.MethodParam.java</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test.Outer.Outer.java</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9008</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test.Outer.Inner.Outer.java</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9009</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>36</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>test.SpecialSeq.SpecialSeq.java</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9010 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CountClassCoupled  CountDeclMethod  CountDeclMethodAll  \\\n",
       "0                   1.0             27.0                27.0   \n",
       "1                   0.0              5.0                 5.0   \n",
       "2                   3.0              2.0                 2.0   \n",
       "3                   3.0             11.0                11.0   \n",
       "4                   1.0             10.0                10.0   \n",
       "5                   5.0              9.0                 9.0   \n",
       "6                   0.0              1.0                 1.0   \n",
       "7                   0.0             19.0                19.0   \n",
       "8                   1.0              5.0                 5.0   \n",
       "9                   4.0              3.0                 3.0   \n",
       "10                  1.0              1.0                 6.0   \n",
       "11                  0.0              1.0                 6.0   \n",
       "12                  7.0             12.0                12.0   \n",
       "13                  1.0              1.0                 1.0   \n",
       "14                  1.0              1.0                 1.0   \n",
       "15                  2.0              1.0                 1.0   \n",
       "16                  2.0              1.0                 1.0   \n",
       "17                  3.0              1.0                 1.0   \n",
       "18                  2.0              1.0                 1.0   \n",
       "19                  4.0              1.0                 1.0   \n",
       "20                  3.0              1.0                 1.0   \n",
       "21                  2.0              1.0                 1.0   \n",
       "22                  2.0              1.0                 1.0   \n",
       "23                  2.0              1.0                 1.0   \n",
       "24                  2.0              1.0                 1.0   \n",
       "25                  2.0              1.0                 1.0   \n",
       "26                  2.0              1.0                 1.0   \n",
       "27                  2.0              1.0                 1.0   \n",
       "28                  2.0              5.0                 5.0   \n",
       "29                  0.0              4.0                 4.0   \n",
       "...                 ...              ...                 ...   \n",
       "8980                0.0              1.0                 1.0   \n",
       "8981                0.0              0.0                 1.0   \n",
       "8982                0.0              1.0                 1.0   \n",
       "8983                0.0              1.0                 1.0   \n",
       "8984                0.0              0.0                 1.0   \n",
       "8985                0.0              1.0                 1.0   \n",
       "8986                0.0              1.0                 1.0   \n",
       "8987                0.0              8.0                 8.0   \n",
       "8988                0.0              4.0                 4.0   \n",
       "8989                0.0              1.0                 1.0   \n",
       "8990                0.0              2.0                 2.0   \n",
       "8991                0.0              1.0                 1.0   \n",
       "8992                1.0              1.0                 1.0   \n",
       "8993                0.0              2.0                 2.0   \n",
       "8994                0.0              1.0                 1.0   \n",
       "8995                0.0              2.0                 2.0   \n",
       "8996                0.0              3.0                 3.0   \n",
       "8997                0.0              1.0                42.0   \n",
       "8998                2.0              3.0                42.0   \n",
       "8999                0.0              2.0                 2.0   \n",
       "9000                0.0              0.0                10.0   \n",
       "9001                2.0              7.0                46.0   \n",
       "9002                2.0              1.0                40.0   \n",
       "9003                0.0              1.0                47.0   \n",
       "9004                1.0              1.0                47.0   \n",
       "9005                2.0              1.0                 1.0   \n",
       "9006                1.0              1.0                 1.0   \n",
       "9007                0.0              0.0                 0.0   \n",
       "9008                0.0              0.0                 0.0   \n",
       "9009                4.0              4.0                43.0   \n",
       "\n",
       "      CountClassDerived  CountLineCode  SumCyclomatic  PercentLackOfCohesion  \\\n",
       "0                   0.0          177.0             77                   88.0   \n",
       "1                   0.0           34.0             15                   80.0   \n",
       "2                   0.0           11.0             45                    0.0   \n",
       "3                   0.0           50.0             88                   72.0   \n",
       "4                   0.0           38.0             29                   60.0   \n",
       "5                   0.0           65.0             26                   72.0   \n",
       "6                   0.0           20.0              5                    0.0   \n",
       "7                   0.0          390.0             74                   83.0   \n",
       "8                   3.0           26.0             88                   50.0   \n",
       "9                   0.0           51.0             10                   33.0   \n",
       "10                  0.0            5.0              0                    0.0   \n",
       "11                  0.0            5.0              0                    0.0   \n",
       "12                  0.0          316.0             24                   79.0   \n",
       "13                  0.0            6.0              0                    0.0   \n",
       "14                  0.0            7.0              0                    0.0   \n",
       "15                  0.0            5.0              0                    0.0   \n",
       "16                  0.0            6.0              0                    0.0   \n",
       "17                  0.0            9.0              0                    0.0   \n",
       "18                  0.0            5.0              0                    0.0   \n",
       "19                  0.0           12.0              0                    0.0   \n",
       "20                  0.0           10.0              0                    0.0   \n",
       "21                  0.0            5.0              0                    0.0   \n",
       "22                  0.0            5.0              0                    0.0   \n",
       "23                  0.0            5.0              0                    0.0   \n",
       "24                  0.0            5.0              0                    0.0   \n",
       "25                  0.0            5.0              0                    0.0   \n",
       "26                  0.0            5.0              0                    0.0   \n",
       "27                  0.0            5.0              0                    0.0   \n",
       "28                  0.0          122.0              4                    0.0   \n",
       "29                  0.0           28.0             61                   58.0   \n",
       "...                 ...            ...            ...                    ...   \n",
       "8980                1.0            6.0              0                    0.0   \n",
       "8981                0.0            2.0              0                    0.0   \n",
       "8982                0.0            5.0              0                    0.0   \n",
       "8983                1.0            7.0              0                    0.0   \n",
       "8984                0.0            2.0              0                    0.0   \n",
       "8985                0.0            4.0             25                    0.0   \n",
       "8986                0.0            4.0             25                    0.0   \n",
       "8987                0.0           38.0              0                    0.0   \n",
       "8988                0.0           14.0              0                    0.0   \n",
       "8989                0.0            4.0             25                    0.0   \n",
       "8990                0.0            8.0             75                    0.0   \n",
       "8991                0.0            5.0             20                    0.0   \n",
       "8992                0.0            9.0              0                    0.0   \n",
       "8993                0.0           14.0             43                    0.0   \n",
       "8994                0.0            4.0              0                    0.0   \n",
       "8995                0.0           10.0              0                    0.0   \n",
       "8996                0.0           23.0             22                    0.0   \n",
       "8997                0.0            4.0              0                    0.0   \n",
       "8998                0.0           20.0              0                   33.0   \n",
       "8999                0.0            8.0              0                   50.0   \n",
       "9000                0.0            2.0              0                    0.0   \n",
       "9001                2.0           42.0              7                   50.0   \n",
       "9002                0.0            5.0              0                    0.0   \n",
       "9003                0.0            5.0             60                    0.0   \n",
       "9004                0.0            5.0             60                    0.0   \n",
       "9005                0.0            5.0              0                    0.0   \n",
       "9006                0.0            5.0              0                    0.0   \n",
       "9007                0.0            4.0              0                    0.0   \n",
       "9008                0.0            2.0              0                    0.0   \n",
       "9009                0.0           25.0             36                   50.0   \n",
       "\n",
       "      MaxInheritanceTree                                               Path  \\\n",
       "0                    1.0   com.oreilly.servlet.MailMessage.MailMessage.java   \n",
       "1                    2.0  com.oreilly.servlet.MailPrintStream.MailMessag...   \n",
       "2                    2.0  org.apache.tools.ant.AllJUnitTests.AllJUnitTes...   \n",
       "3                    2.0    org.apache.tools.ant.BuildEvent.BuildEvent.java   \n",
       "4                    2.0  org.apache.tools.ant.BuildException.BuildExcep...   \n",
       "5                    1.0  org.apache.tools.ant.DefaultLogger.DefaultLogg...   \n",
       "6                    1.0  org.apache.tools.ant.DesirableFilter.Desirable...   \n",
       "7                    1.0  org.apache.tools.ant.DirectoryScanner.Director...   \n",
       "8                    1.0  org.apache.tools.ant.EnumeratedAttribute.Enume...   \n",
       "9                    2.0  org.apache.tools.ant.EnumeratedAttributeTest.E...   \n",
       "10                   2.0  org.apache.tools.ant.EnumeratedAttributeTest.T...   \n",
       "11                   2.0  org.apache.tools.ant.EnumeratedAttributeTest.T...   \n",
       "12                   1.0  org.apache.tools.ant.IntrospectionHelper.Intro...   \n",
       "13                   1.0  org.apache.tools.ant.IntrospectionHelper.Intro...   \n",
       "14                   1.0  org.apache.tools.ant.IntrospectionHelper.Intro...   \n",
       "15                   1.0  org.apache.tools.ant.IntrospectionHelper.creat...   \n",
       "16                   1.0  org.apache.tools.ant.IntrospectionHelper.creat...   \n",
       "17                   1.0  org.apache.tools.ant.IntrospectionHelper.creat...   \n",
       "18                   1.0  org.apache.tools.ant.IntrospectionHelper.creat...   \n",
       "19                   1.0  org.apache.tools.ant.IntrospectionHelper.creat...   \n",
       "20                   1.0  org.apache.tools.ant.IntrospectionHelper.creat...   \n",
       "21                   1.0  org.apache.tools.ant.IntrospectionHelper.creat...   \n",
       "22                   1.0  org.apache.tools.ant.IntrospectionHelper.creat...   \n",
       "23                   1.0  org.apache.tools.ant.IntrospectionHelper.creat...   \n",
       "24                   1.0  org.apache.tools.ant.IntrospectionHelper.creat...   \n",
       "25                   1.0  org.apache.tools.ant.IntrospectionHelper.creat...   \n",
       "26                   1.0  org.apache.tools.ant.IntrospectionHelper.creat...   \n",
       "27                   1.0  org.apache.tools.ant.IntrospectionHelper.creat...   \n",
       "28                   2.0  org.apache.tools.ant.IntrospectionHelperTest.I...   \n",
       "29                   1.0        org.apache.tools.ant.Location.Location.java   \n",
       "...                  ...                                                ...   \n",
       "8980                 2.0  org.example.junit.AbstractJUnit3TestNotMissed....   \n",
       "8981                 3.0  org.example.junit.AbstractJUnit3TestNotMissed....   \n",
       "8982                 1.0  org.example.junit.AbstractTestMissed.AbstractT...   \n",
       "8983                 1.0  org.example.junit.AbstractTestNotMissed.Abstra...   \n",
       "8984                 2.0  org.example.junit.AbstractTestNotMissed.InnerA...   \n",
       "8985                 2.0  org.example.junit.JUnit3NonTestMissed.JUnit3No...   \n",
       "8986                 2.0  org.example.junit.JUnit3TestNotMissed.JUnit3Te...   \n",
       "8987                 1.0  org.example.junit.JUnit4Skippable.JUnit4Skippa...   \n",
       "8988                 2.0  org.example.junit.MultilineAsserts.MultilineAs...   \n",
       "8989                 1.0  org.example.junit.NonTestMissed.NonTestMissed....   \n",
       "8990                 2.0               org.example.junit.Output.Output.java   \n",
       "8991                 1.0  org.example.junit.TestNotMissed.TestNotMissed....   \n",
       "8992                 1.0  org.example.junit.TestWithSuiteNotMissed.TestW...   \n",
       "8993                 2.0  org.example.junit.ThreadedOutput.ThreadedOutpu...   \n",
       "8994                 2.0  org.example.junit.ThreadedOutput.testOutput.(A...   \n",
       "8995                 1.0             org.example.junit.Timeout.Timeout.java   \n",
       "8996                 1.0  org.example.junit.XmlParserTest.XmlParserTest....   \n",
       "8997                 4.0  org.example.tasks.TaskdefTestContainerTask.Tas...   \n",
       "8998                 3.0  org.example.tasks.TaskdefTestSimpleTask.Taskde...   \n",
       "8999                 1.0  org.example.tasks.TaskdefTestSimpleTask.Echo.T...   \n",
       "9000                 2.0  org.example.types.TypedefTestType.TypedefTestT...   \n",
       "9001                 3.0                        task.BaseTask.BaseTask.java   \n",
       "9002                 3.0                task.EchoLocation.EchoLocation.java   \n",
       "9003                 4.0                task.UUDecodeTask.UUDecodeTask.java   \n",
       "9004                 4.0                task.UUEncodeTask.UUEncodeTask.java   \n",
       "9005                 1.0      test.ContainsOnlyInner.ContainsOnlyInner.java   \n",
       "9006                 1.0                  test.MethodParam.MethodParam.java   \n",
       "9007                 1.0                              test.Outer.Outer.java   \n",
       "9008                 1.0                        test.Outer.Inner.Outer.java   \n",
       "9009                 3.0                    test.SpecialSeq.SpecialSeq.java   \n",
       "\n",
       "      will_change  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               1  \n",
       "5               1  \n",
       "6               0  \n",
       "7               1  \n",
       "8               0  \n",
       "9               0  \n",
       "10              0  \n",
       "11              0  \n",
       "12              1  \n",
       "13              0  \n",
       "14              0  \n",
       "15              0  \n",
       "16              0  \n",
       "17              0  \n",
       "18              0  \n",
       "19              1  \n",
       "20              1  \n",
       "21              0  \n",
       "22              0  \n",
       "23              0  \n",
       "24              0  \n",
       "25              0  \n",
       "26              0  \n",
       "27              0  \n",
       "28              1  \n",
       "29              0  \n",
       "...           ...  \n",
       "8980            0  \n",
       "8981            0  \n",
       "8982            0  \n",
       "8983            0  \n",
       "8984            0  \n",
       "8985            0  \n",
       "8986            0  \n",
       "8987            0  \n",
       "8988            0  \n",
       "8989            0  \n",
       "8990            0  \n",
       "8991            0  \n",
       "8992            0  \n",
       "8993            1  \n",
       "8994            0  \n",
       "8995            0  \n",
       "8996            0  \n",
       "8997            0  \n",
       "8998            0  \n",
       "8999            0  \n",
       "9000            0  \n",
       "9001            0  \n",
       "9002            0  \n",
       "9003            0  \n",
       "9004            0  \n",
       "9005            0  \n",
       "9006            0  \n",
       "9007            0  \n",
       "9008            0  \n",
       "9009            1  \n",
       "\n",
       "[9010 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_releases_df = pd.read_csv('all_releases.csv')\n",
    "\n",
    "#all_releases_df.head()\n",
    "\n",
    "print(\"Generating a new dataframe without containing the last release...\")\n",
    "df = all_releases_df[all_releases_df['release'] != all_releases_df['release'].max()]\n",
    "print(\"... DONE!\")\n",
    "\n",
    "df.drop(columns=['class_frequency', 'number_of_changes', 'release', 'Name', 'Kind', 'File'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window_size: 2\n",
      "generating tensor...\n",
      "...DONE!\n",
      "tensor dimensions:\n",
      "tensor input X: (6080, 8, 2)\n",
      "tensor input y: (6080, 2)\n",
      "proportion of y labels: (array([0, 1]), array([2642, 3438]))\n",
      "Splitting dataset into Train and Test sets...\n",
      "Tensor X train: (4256, 2, 8)\n",
      "Tensor y train: (4256, 2)\n",
      "Tensor X test: (1824, 2, 8)\n",
      "Tensor y test: (1824, 2)\n",
      "computing weights...\n",
      "... DONE!\n",
      "setting stratified k-fold...\n",
      "number of k: 5\n",
      "... DONE!\n",
      "Executing algorithm...\n",
      "number of epochs: 20\n",
      "number of batch: 512\n",
      "Training on fold 1/5...\n",
      "model dim:  (2, 8) 2\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 2, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 2, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-1-fb283a009ca9>:2: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3404 samples, validate on 852 samples\n",
      "Epoch 1/20\n",
      "3404/3404 [==============================] - 1s 270us/step - loss: 0.3085 - acc: 0.6369 - auc: 0.7029 - f1: 0.6369 - val_loss: 0.2906 - val_acc: 0.7054 - val_auc: 0.7610 - val_f1: 0.7054\n",
      "Epoch 2/20\n",
      "3404/3404 [==============================] - 0s 40us/step - loss: 0.2808 - acc: 0.7071 - auc: 0.7753 - f1: 0.7071 - val_loss: 0.2797 - val_acc: 0.7066 - val_auc: 0.7752 - val_f1: 0.7066\n",
      "Epoch 3/20\n",
      "3404/3404 [==============================] - 0s 39us/step - loss: 0.2771 - acc: 0.7177 - auc: 0.7828 - f1: 0.7177 - val_loss: 0.2811 - val_acc: 0.6972 - val_auc: 0.7787 - val_f1: 0.6972\n",
      "Epoch 4/20\n",
      "3404/3404 [==============================] - 0s 40us/step - loss: 0.2716 - acc: 0.7241 - auc: 0.7915 - f1: 0.7241 - val_loss: 0.2751 - val_acc: 0.7007 - val_auc: 0.7828 - val_f1: 0.7007\n",
      "Epoch 5/20\n",
      "3404/3404 [==============================] - 0s 41us/step - loss: 0.2687 - acc: 0.7233 - auc: 0.7965 - f1: 0.7233 - val_loss: 0.2719 - val_acc: 0.6984 - val_auc: 0.7901 - val_f1: 0.6984\n",
      "Epoch 6/20\n",
      "3404/3404 [==============================] - 0s 40us/step - loss: 0.2634 - acc: 0.7327 - auc: 0.8065 - f1: 0.7327 - val_loss: 0.2677 - val_acc: 0.7136 - val_auc: 0.7969 - val_f1: 0.7136\n",
      "Epoch 7/20\n",
      "3404/3404 [==============================] - 0s 40us/step - loss: 0.2594 - acc: 0.7406 - auc: 0.8126 - f1: 0.7406 - val_loss: 0.2632 - val_acc: 0.7242 - val_auc: 0.8041 - val_f1: 0.7242\n",
      "Epoch 8/20\n",
      "3404/3404 [==============================] - 0s 42us/step - loss: 0.2556 - acc: 0.7391 - auc: 0.8202 - f1: 0.7391 - val_loss: 0.2602 - val_acc: 0.7347 - val_auc: 0.8109 - val_f1: 0.7347\n",
      "Epoch 9/20\n",
      "3404/3404 [==============================] - 0s 41us/step - loss: 0.2557 - acc: 0.7356 - auc: 0.8223 - f1: 0.7356 - val_loss: 0.2547 - val_acc: 0.7383 - val_auc: 0.8184 - val_f1: 0.7383\n",
      "Epoch 10/20\n",
      "3404/3404 [==============================] - 0s 43us/step - loss: 0.2501 - acc: 0.7465 - auc: 0.8317 - f1: 0.7465 - val_loss: 0.2549 - val_acc: 0.7512 - val_auc: 0.8244 - val_f1: 0.7512\n",
      "Epoch 11/20\n",
      "3404/3404 [==============================] - 0s 43us/step - loss: 0.2473 - acc: 0.7576 - auc: 0.8336 - f1: 0.7576 - val_loss: 0.2526 - val_acc: 0.7453 - val_auc: 0.8236 - val_f1: 0.7453\n",
      "Epoch 12/20\n",
      "3404/3404 [==============================] - 0s 42us/step - loss: 0.2430 - acc: 0.7571 - auc: 0.8397 - f1: 0.7571 - val_loss: 0.2469 - val_acc: 0.7465 - val_auc: 0.8329 - val_f1: 0.7465\n",
      "Epoch 13/20\n",
      "3404/3404 [==============================] - 0s 43us/step - loss: 0.2403 - acc: 0.7585 - auc: 0.8457 - f1: 0.7585 - val_loss: 0.2472 - val_acc: 0.7512 - val_auc: 0.8323 - val_f1: 0.7512\n",
      "Epoch 14/20\n",
      "3404/3404 [==============================] - 0s 42us/step - loss: 0.2409 - acc: 0.7647 - auc: 0.8466 - f1: 0.7647 - val_loss: 0.2416 - val_acc: 0.7488 - val_auc: 0.8408 - val_f1: 0.7488\n",
      "Epoch 15/20\n",
      "3404/3404 [==============================] - 0s 41us/step - loss: 0.2336 - acc: 0.7726 - auc: 0.8548 - f1: 0.7726 - val_loss: 0.2502 - val_acc: 0.7406 - val_auc: 0.8312 - val_f1: 0.7406\n",
      "Epoch 16/20\n",
      "3404/3404 [==============================] - 0s 41us/step - loss: 0.2322 - acc: 0.7782 - auc: 0.8543 - f1: 0.7782 - val_loss: 0.2393 - val_acc: 0.7582 - val_auc: 0.8449 - val_f1: 0.7582\n",
      "Epoch 17/20\n",
      "3404/3404 [==============================] - 0s 40us/step - loss: 0.2297 - acc: 0.7735 - auc: 0.8579 - f1: 0.7735 - val_loss: 0.2425 - val_acc: 0.7523 - val_auc: 0.8396 - val_f1: 0.7523\n",
      "Epoch 18/20\n",
      "3404/3404 [==============================] - 0s 41us/step - loss: 0.2291 - acc: 0.7750 - auc: 0.8594 - f1: 0.7750 - val_loss: 0.2401 - val_acc: 0.7594 - val_auc: 0.8450 - val_f1: 0.7594\n",
      "Epoch 19/20\n",
      "3404/3404 [==============================] - 0s 43us/step - loss: 0.2227 - acc: 0.7894 - auc: 0.8690 - f1: 0.7894 - val_loss: 0.2397 - val_acc: 0.7723 - val_auc: 0.8491 - val_f1: 0.7723\n",
      "Epoch 20/20\n",
      "3404/3404 [==============================] - 0s 41us/step - loss: 0.2196 - acc: 0.7864 - auc: 0.8728 - f1: 0.7864 - val_loss: 0.2404 - val_acc: 0.7688 - val_auc: 0.8463 - val_f1: 0.7688\n",
      "[[264 102]\n",
      " [ 95 391]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73       366\n",
      "           1       0.79      0.80      0.80       486\n",
      "\n",
      "    accuracy                           0.77       852\n",
      "   macro avg       0.76      0.76      0.76       852\n",
      "weighted avg       0.77      0.77      0.77       852\n",
      "\n",
      "Training on fold 2/5...\n",
      "model dim:  (2, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_4 (GRU)                  (None, 2, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 2, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3404 samples, validate on 852 samples\n",
      "Epoch 1/20\n",
      "3404/3404 [==============================] - 1s 320us/step - loss: 0.3090 - acc: 0.6451 - auc: 0.6998 - f1: 0.6451 - val_loss: 0.2871 - val_acc: 0.7160 - val_auc: 0.7737 - val_f1: 0.7160\n",
      "Epoch 2/20\n",
      "3404/3404 [==============================] - 0s 39us/step - loss: 0.2856 - acc: 0.7089 - auc: 0.7680 - f1: 0.7089 - val_loss: 0.2749 - val_acc: 0.7148 - val_auc: 0.7906 - val_f1: 0.7148\n",
      "Epoch 3/20\n",
      "3404/3404 [==============================] - 0s 41us/step - loss: 0.2809 - acc: 0.7068 - auc: 0.7715 - f1: 0.7068 - val_loss: 0.2699 - val_acc: 0.7230 - val_auc: 0.7971 - val_f1: 0.7230\n",
      "Epoch 4/20\n",
      "3404/3404 [==============================] - 0s 40us/step - loss: 0.2776 - acc: 0.7109 - auc: 0.7811 - f1: 0.7109 - val_loss: 0.2679 - val_acc: 0.7242 - val_auc: 0.8031 - val_f1: 0.7242\n",
      "Epoch 5/20\n",
      "3404/3404 [==============================] - 0s 41us/step - loss: 0.2700 - acc: 0.7206 - auc: 0.7936 - f1: 0.7206 - val_loss: 0.2647 - val_acc: 0.7265 - val_auc: 0.8055 - val_f1: 0.7265\n",
      "Epoch 6/20\n",
      "3404/3404 [==============================] - 0s 42us/step - loss: 0.2691 - acc: 0.7194 - auc: 0.7943 - f1: 0.7194 - val_loss: 0.2641 - val_acc: 0.7383 - val_auc: 0.8121 - val_f1: 0.7383\n",
      "Epoch 7/20\n",
      "3404/3404 [==============================] - 0s 41us/step - loss: 0.2648 - acc: 0.7341 - auc: 0.8043 - f1: 0.7341 - val_loss: 0.2584 - val_acc: 0.7394 - val_auc: 0.8159 - val_f1: 0.7394\n",
      "Epoch 8/20\n",
      "3404/3404 [==============================] - 0s 41us/step - loss: 0.2589 - acc: 0.7324 - auc: 0.8173 - f1: 0.7324 - val_loss: 0.2563 - val_acc: 0.7418 - val_auc: 0.8188 - val_f1: 0.7418\n",
      "Epoch 9/20\n",
      "3404/3404 [==============================] - 0s 43us/step - loss: 0.2560 - acc: 0.7421 - auc: 0.8192 - f1: 0.7421 - val_loss: 0.2568 - val_acc: 0.7418 - val_auc: 0.8247 - val_f1: 0.7418\n",
      "Epoch 10/20\n",
      "3404/3404 [==============================] - 0s 42us/step - loss: 0.2495 - acc: 0.7521 - auc: 0.8308 - f1: 0.7521 - val_loss: 0.2519 - val_acc: 0.7430 - val_auc: 0.8286 - val_f1: 0.7430\n",
      "Epoch 11/20\n",
      "3404/3404 [==============================] - 0s 42us/step - loss: 0.2459 - acc: 0.7500 - auc: 0.8349 - f1: 0.7500 - val_loss: 0.2536 - val_acc: 0.7523 - val_auc: 0.8326 - val_f1: 0.7523\n",
      "Epoch 12/20\n",
      "3404/3404 [==============================] - 0s 42us/step - loss: 0.2469 - acc: 0.7547 - auc: 0.8352 - f1: 0.7547 - val_loss: 0.2463 - val_acc: 0.7523 - val_auc: 0.8356 - val_f1: 0.7523\n",
      "Epoch 13/20\n",
      "3404/3404 [==============================] - 0s 42us/step - loss: 0.2386 - acc: 0.7665 - auc: 0.8459 - f1: 0.7665 - val_loss: 0.2474 - val_acc: 0.7465 - val_auc: 0.8370 - val_f1: 0.7465\n",
      "Epoch 14/20\n",
      "3404/3404 [==============================] - 0s 42us/step - loss: 0.2376 - acc: 0.7714 - auc: 0.8478 - f1: 0.7714 - val_loss: 0.2487 - val_acc: 0.7394 - val_auc: 0.8363 - val_f1: 0.7394\n",
      "Epoch 15/20\n",
      "3404/3404 [==============================] - 0s 42us/step - loss: 0.2347 - acc: 0.7697 - auc: 0.8559 - f1: 0.7697 - val_loss: 0.2452 - val_acc: 0.7641 - val_auc: 0.8448 - val_f1: 0.7641\n",
      "Epoch 16/20\n",
      "3404/3404 [==============================] - 0s 43us/step - loss: 0.2341 - acc: 0.7717 - auc: 0.8549 - f1: 0.7717 - val_loss: 0.2489 - val_acc: 0.7629 - val_auc: 0.8482 - val_f1: 0.7629\n",
      "Epoch 17/20\n",
      "3404/3404 [==============================] - 0s 43us/step - loss: 0.2306 - acc: 0.7729 - auc: 0.8607 - f1: 0.7729 - val_loss: 0.2436 - val_acc: 0.7723 - val_auc: 0.8495 - val_f1: 0.7723\n",
      "Epoch 18/20\n",
      "3404/3404 [==============================] - 0s 43us/step - loss: 0.2296 - acc: 0.7782 - auc: 0.8643 - f1: 0.7782 - val_loss: 0.2346 - val_acc: 0.7723 - val_auc: 0.8535 - val_f1: 0.7723\n",
      "Epoch 19/20\n",
      "3404/3404 [==============================] - 0s 43us/step - loss: 0.2249 - acc: 0.7900 - auc: 0.8664 - f1: 0.7900 - val_loss: 0.2320 - val_acc: 0.7735 - val_auc: 0.8576 - val_f1: 0.7735\n",
      "Epoch 20/20\n",
      "3404/3404 [==============================] - 0s 42us/step - loss: 0.2172 - acc: 0.7947 - auc: 0.8765 - f1: 0.7947 - val_loss: 0.2336 - val_acc: 0.7758 - val_auc: 0.8589 - val_f1: 0.7758\n",
      "[[255 111]\n",
      " [ 80 406]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.70      0.73       366\n",
      "           1       0.79      0.84      0.81       486\n",
      "\n",
      "    accuracy                           0.78       852\n",
      "   macro avg       0.77      0.77      0.77       852\n",
      "weighted avg       0.77      0.78      0.77       852\n",
      "\n",
      "Training on fold 3/5...\n",
      "model dim:  (2, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_7 (GRU)                  (None, 2, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 2, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3405 samples, validate on 851 samples\n",
      "Epoch 1/20\n",
      "3405/3405 [==============================] - 1s 382us/step - loss: 0.3051 - acc: 0.6537 - auc: 0.7087 - f1: 0.6537 - val_loss: 0.3121 - val_acc: 0.6745 - val_auc: 0.7361 - val_f1: 0.6745\n",
      "Epoch 2/20\n",
      "3405/3405 [==============================] - 0s 40us/step - loss: 0.2814 - acc: 0.7151 - auc: 0.7757 - f1: 0.7151 - val_loss: 0.2923 - val_acc: 0.6874 - val_auc: 0.7554 - val_f1: 0.6874\n",
      "Epoch 3/20\n",
      "3405/3405 [==============================] - 0s 41us/step - loss: 0.2789 - acc: 0.7201 - auc: 0.7787 - f1: 0.7201 - val_loss: 0.2867 - val_acc: 0.6898 - val_auc: 0.7626 - val_f1: 0.6898\n",
      "Epoch 4/20\n",
      "3405/3405 [==============================] - 0s 43us/step - loss: 0.2725 - acc: 0.7225 - auc: 0.7906 - f1: 0.7225 - val_loss: 0.2895 - val_acc: 0.6933 - val_auc: 0.7641 - val_f1: 0.6933\n",
      "Epoch 5/20\n",
      "3405/3405 [==============================] - 0s 41us/step - loss: 0.2695 - acc: 0.7239 - auc: 0.7980 - f1: 0.7239 - val_loss: 0.2864 - val_acc: 0.6863 - val_auc: 0.7672 - val_f1: 0.6863\n",
      "Epoch 6/20\n",
      "3405/3405 [==============================] - 0s 42us/step - loss: 0.2641 - acc: 0.7327 - auc: 0.8055 - f1: 0.7327 - val_loss: 0.2827 - val_acc: 0.7027 - val_auc: 0.7725 - val_f1: 0.7027\n",
      "Epoch 7/20\n",
      "3405/3405 [==============================] - 0s 44us/step - loss: 0.2616 - acc: 0.7339 - auc: 0.8091 - f1: 0.7339 - val_loss: 0.2808 - val_acc: 0.6921 - val_auc: 0.7763 - val_f1: 0.6921\n",
      "Epoch 8/20\n",
      "3405/3405 [==============================] - 0s 44us/step - loss: 0.2549 - acc: 0.7451 - auc: 0.8209 - f1: 0.7451 - val_loss: 0.2797 - val_acc: 0.7062 - val_auc: 0.7819 - val_f1: 0.7062\n",
      "Epoch 9/20\n",
      "3405/3405 [==============================] - 0s 42us/step - loss: 0.2513 - acc: 0.7527 - auc: 0.8267 - f1: 0.7527 - val_loss: 0.2737 - val_acc: 0.7098 - val_auc: 0.7893 - val_f1: 0.7098\n",
      "Epoch 10/20\n",
      "3405/3405 [==============================] - 0s 42us/step - loss: 0.2485 - acc: 0.7536 - auc: 0.8317 - f1: 0.7536 - val_loss: 0.2691 - val_acc: 0.7227 - val_auc: 0.7968 - val_f1: 0.7227\n",
      "Epoch 11/20\n",
      "3405/3405 [==============================] - 0s 43us/step - loss: 0.2408 - acc: 0.7621 - auc: 0.8439 - f1: 0.7621 - val_loss: 0.2751 - val_acc: 0.7121 - val_auc: 0.7988 - val_f1: 0.7121\n",
      "Epoch 12/20\n",
      "3405/3405 [==============================] - 0s 43us/step - loss: 0.2393 - acc: 0.7615 - auc: 0.8461 - f1: 0.7615 - val_loss: 0.2616 - val_acc: 0.7203 - val_auc: 0.8101 - val_f1: 0.7203\n",
      "Epoch 13/20\n",
      "3405/3405 [==============================] - 0s 42us/step - loss: 0.2329 - acc: 0.7712 - auc: 0.8556 - f1: 0.7712 - val_loss: 0.2713 - val_acc: 0.7109 - val_auc: 0.8069 - val_f1: 0.7109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "3405/3405 [==============================] - 0s 42us/step - loss: 0.2341 - acc: 0.7715 - auc: 0.8554 - f1: 0.7715 - val_loss: 0.2645 - val_acc: 0.7368 - val_auc: 0.8154 - val_f1: 0.7368\n",
      "Epoch 15/20\n",
      "3405/3405 [==============================] - 0s 42us/step - loss: 0.2288 - acc: 0.7715 - auc: 0.8618 - f1: 0.7715 - val_loss: 0.2632 - val_acc: 0.7427 - val_auc: 0.8175 - val_f1: 0.7427\n",
      "Epoch 16/20\n",
      "3405/3405 [==============================] - 0s 43us/step - loss: 0.2296 - acc: 0.7809 - auc: 0.8623 - f1: 0.7809 - val_loss: 0.2585 - val_acc: 0.7403 - val_auc: 0.8209 - val_f1: 0.7403\n",
      "Epoch 17/20\n",
      "3405/3405 [==============================] - 0s 43us/step - loss: 0.2258 - acc: 0.7803 - auc: 0.8668 - f1: 0.7803 - val_loss: 0.2569 - val_acc: 0.7474 - val_auc: 0.8249 - val_f1: 0.7474\n",
      "Epoch 18/20\n",
      "3405/3405 [==============================] - 0s 42us/step - loss: 0.2213 - acc: 0.7903 - auc: 0.8703 - f1: 0.7903 - val_loss: 0.2592 - val_acc: 0.7286 - val_auc: 0.8246 - val_f1: 0.7286\n",
      "Epoch 19/20\n",
      "3405/3405 [==============================] - 0s 43us/step - loss: 0.2183 - acc: 0.7938 - auc: 0.8788 - f1: 0.7938 - val_loss: 0.2638 - val_acc: 0.7403 - val_auc: 0.8218 - val_f1: 0.7403\n",
      "Epoch 20/20\n",
      "3405/3405 [==============================] - 0s 42us/step - loss: 0.2110 - acc: 0.7979 - auc: 0.8842 - f1: 0.7979 - val_loss: 0.2568 - val_acc: 0.7579 - val_auc: 0.8307 - val_f1: 0.7579\n",
      "[[243 123]\n",
      " [ 83 402]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.66      0.70       366\n",
      "           1       0.77      0.83      0.80       485\n",
      "\n",
      "    accuracy                           0.76       851\n",
      "   macro avg       0.76      0.75      0.75       851\n",
      "weighted avg       0.76      0.76      0.76       851\n",
      "\n",
      "Training on fold 4/5...\n",
      "model dim:  (2, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_10 (GRU)                 (None, 2, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 2, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_12 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3405 samples, validate on 851 samples\n",
      "Epoch 1/20\n",
      "3405/3405 [==============================] - 1s 437us/step - loss: 0.3086 - acc: 0.6470 - auc: 0.7094 - f1: 0.6470 - val_loss: 0.2850 - val_acc: 0.7203 - val_auc: 0.7771 - val_f1: 0.7203\n",
      "Epoch 2/20\n",
      "3405/3405 [==============================] - 0s 41us/step - loss: 0.2918 - acc: 0.6957 - auc: 0.7588 - f1: 0.6957 - val_loss: 0.2746 - val_acc: 0.7203 - val_auc: 0.7895 - val_f1: 0.7203\n",
      "Epoch 3/20\n",
      "3405/3405 [==============================] - 0s 41us/step - loss: 0.2826 - acc: 0.7040 - auc: 0.7688 - f1: 0.7040 - val_loss: 0.2669 - val_acc: 0.7391 - val_auc: 0.8016 - val_f1: 0.7391\n",
      "Epoch 4/20\n",
      "3405/3405 [==============================] - 0s 41us/step - loss: 0.2761 - acc: 0.7145 - auc: 0.7809 - f1: 0.7145 - val_loss: 0.2672 - val_acc: 0.7356 - val_auc: 0.8040 - val_f1: 0.7356\n",
      "Epoch 5/20\n",
      "3405/3405 [==============================] - 0s 41us/step - loss: 0.2725 - acc: 0.7137 - auc: 0.7902 - f1: 0.7137 - val_loss: 0.2642 - val_acc: 0.7333 - val_auc: 0.8051 - val_f1: 0.7333\n",
      "Epoch 6/20\n",
      "3405/3405 [==============================] - 0s 44us/step - loss: 0.2683 - acc: 0.7272 - auc: 0.7971 - f1: 0.7272 - val_loss: 0.2637 - val_acc: 0.7239 - val_auc: 0.8110 - val_f1: 0.7239\n",
      "Epoch 7/20\n",
      "3405/3405 [==============================] - 0s 42us/step - loss: 0.2619 - acc: 0.7313 - auc: 0.8090 - f1: 0.7313 - val_loss: 0.2561 - val_acc: 0.7427 - val_auc: 0.8193 - val_f1: 0.7427\n",
      "Epoch 8/20\n",
      "3405/3405 [==============================] - 0s 42us/step - loss: 0.2612 - acc: 0.7348 - auc: 0.8108 - f1: 0.7348 - val_loss: 0.2512 - val_acc: 0.7462 - val_auc: 0.8271 - val_f1: 0.7462\n",
      "Epoch 9/20\n",
      "3405/3405 [==============================] - 0s 43us/step - loss: 0.2588 - acc: 0.7366 - auc: 0.8147 - f1: 0.7366 - val_loss: 0.2477 - val_acc: 0.7556 - val_auc: 0.8340 - val_f1: 0.7556\n",
      "Epoch 10/20\n",
      "3405/3405 [==============================] - 0s 43us/step - loss: 0.2518 - acc: 0.7545 - auc: 0.8270 - f1: 0.7545 - val_loss: 0.2525 - val_acc: 0.7380 - val_auc: 0.8354 - val_f1: 0.7380\n",
      "Epoch 11/20\n",
      "3405/3405 [==============================] - 0s 43us/step - loss: 0.2506 - acc: 0.7498 - auc: 0.8311 - f1: 0.7498 - val_loss: 0.2492 - val_acc: 0.7462 - val_auc: 0.8407 - val_f1: 0.7462\n",
      "Epoch 12/20\n",
      "3405/3405 [==============================] - 0s 42us/step - loss: 0.2432 - acc: 0.7577 - auc: 0.8387 - f1: 0.7577 - val_loss: 0.2433 - val_acc: 0.7544 - val_auc: 0.8420 - val_f1: 0.7544\n",
      "Epoch 13/20\n",
      "3405/3405 [==============================] - 0s 43us/step - loss: 0.2397 - acc: 0.7624 - auc: 0.8459 - f1: 0.7624 - val_loss: 0.2427 - val_acc: 0.7685 - val_auc: 0.8464 - val_f1: 0.7685\n",
      "Epoch 14/20\n",
      "3405/3405 [==============================] - 0s 42us/step - loss: 0.2430 - acc: 0.7504 - auc: 0.8435 - f1: 0.7504 - val_loss: 0.2391 - val_acc: 0.7615 - val_auc: 0.8463 - val_f1: 0.7615\n",
      "Epoch 15/20\n",
      "3405/3405 [==============================] - 0s 43us/step - loss: 0.2369 - acc: 0.7671 - auc: 0.8526 - f1: 0.7671 - val_loss: 0.2368 - val_acc: 0.7579 - val_auc: 0.8539 - val_f1: 0.7579\n",
      "Epoch 16/20\n",
      "3405/3405 [==============================] - 0s 44us/step - loss: 0.2338 - acc: 0.7683 - auc: 0.8559 - f1: 0.7683 - val_loss: 0.2409 - val_acc: 0.7485 - val_auc: 0.8537 - val_f1: 0.7485\n",
      "Epoch 17/20\n",
      "3405/3405 [==============================] - 0s 42us/step - loss: 0.2329 - acc: 0.7689 - auc: 0.8561 - f1: 0.7689 - val_loss: 0.2353 - val_acc: 0.7685 - val_auc: 0.8539 - val_f1: 0.7685\n",
      "Epoch 18/20\n",
      "3405/3405 [==============================] - 0s 42us/step - loss: 0.2267 - acc: 0.7818 - auc: 0.8644 - f1: 0.7818 - val_loss: 0.2327 - val_acc: 0.7697 - val_auc: 0.8599 - val_f1: 0.7697\n",
      "Epoch 19/20\n",
      "3405/3405 [==============================] - 0s 45us/step - loss: 0.2270 - acc: 0.7791 - auc: 0.8639 - f1: 0.7791 - val_loss: 0.2319 - val_acc: 0.7720 - val_auc: 0.8567 - val_f1: 0.7720\n",
      "Epoch 20/20\n",
      "3405/3405 [==============================] - 0s 44us/step - loss: 0.2259 - acc: 0.7836 - auc: 0.8630 - f1: 0.7836 - val_loss: 0.2312 - val_acc: 0.7662 - val_auc: 0.8616 - val_f1: 0.7662\n",
      "[[297  69]\n",
      " [130 355]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.81      0.75       366\n",
      "           1       0.84      0.73      0.78       485\n",
      "\n",
      "    accuracy                           0.77       851\n",
      "   macro avg       0.77      0.77      0.77       851\n",
      "weighted avg       0.78      0.77      0.77       851\n",
      "\n",
      "Training on fold 5/5...\n",
      "model dim:  (2, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_13 (GRU)                 (None, 2, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_14 (GRU)                 (None, 2, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_15 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3406 samples, validate on 850 samples\n",
      "Epoch 1/20\n",
      "3406/3406 [==============================] - 2s 493us/step - loss: 0.3055 - acc: 0.6515 - auc: 0.7115 - f1: 0.6515 - val_loss: 0.2718 - val_acc: 0.7282 - val_auc: 0.7941 - val_f1: 0.7282\n",
      "Epoch 2/20\n",
      "3406/3406 [==============================] - 0s 40us/step - loss: 0.2882 - acc: 0.7043 - auc: 0.7597 - f1: 0.7043 - val_loss: 0.2671 - val_acc: 0.7294 - val_auc: 0.8022 - val_f1: 0.7294\n",
      "Epoch 3/20\n",
      "3406/3406 [==============================] - 0s 41us/step - loss: 0.2819 - acc: 0.7061 - auc: 0.7709 - f1: 0.7061 - val_loss: 0.2662 - val_acc: 0.7259 - val_auc: 0.8010 - val_f1: 0.7259\n",
      "Epoch 4/20\n",
      "3406/3406 [==============================] - 0s 40us/step - loss: 0.2794 - acc: 0.7055 - auc: 0.7763 - f1: 0.7055 - val_loss: 0.2600 - val_acc: 0.7447 - val_auc: 0.8114 - val_f1: 0.7447\n",
      "Epoch 5/20\n",
      "3406/3406 [==============================] - 0s 42us/step - loss: 0.2738 - acc: 0.7176 - auc: 0.7886 - f1: 0.7176 - val_loss: 0.2568 - val_acc: 0.7388 - val_auc: 0.8176 - val_f1: 0.7388\n",
      "Epoch 6/20\n",
      "3406/3406 [==============================] - 0s 42us/step - loss: 0.2686 - acc: 0.7237 - auc: 0.7943 - f1: 0.7237 - val_loss: 0.2538 - val_acc: 0.7459 - val_auc: 0.8219 - val_f1: 0.7459\n",
      "Epoch 7/20\n",
      "3406/3406 [==============================] - 0s 41us/step - loss: 0.2684 - acc: 0.7249 - auc: 0.7972 - f1: 0.7249 - val_loss: 0.2509 - val_acc: 0.7529 - val_auc: 0.8283 - val_f1: 0.7529\n",
      "Epoch 8/20\n",
      "3406/3406 [==============================] - 0s 42us/step - loss: 0.2625 - acc: 0.7281 - auc: 0.8079 - f1: 0.7281 - val_loss: 0.2493 - val_acc: 0.7400 - val_auc: 0.8387 - val_f1: 0.7400\n",
      "Epoch 9/20\n",
      "3406/3406 [==============================] - 0s 42us/step - loss: 0.2577 - acc: 0.7419 - auc: 0.8174 - f1: 0.7419 - val_loss: 0.2432 - val_acc: 0.7600 - val_auc: 0.8405 - val_f1: 0.7600\n",
      "Epoch 10/20\n",
      "3406/3406 [==============================] - 0s 42us/step - loss: 0.2550 - acc: 0.7390 - auc: 0.8204 - f1: 0.7390 - val_loss: 0.2383 - val_acc: 0.7694 - val_auc: 0.8480 - val_f1: 0.7694\n",
      "Epoch 11/20\n",
      "3406/3406 [==============================] - 0s 42us/step - loss: 0.2491 - acc: 0.7472 - auc: 0.8327 - f1: 0.7472 - val_loss: 0.2385 - val_acc: 0.7918 - val_auc: 0.8510 - val_f1: 0.7918\n",
      "Epoch 12/20\n",
      "3406/3406 [==============================] - 0s 42us/step - loss: 0.2444 - acc: 0.7531 - auc: 0.8408 - f1: 0.7531 - val_loss: 0.2327 - val_acc: 0.7788 - val_auc: 0.8569 - val_f1: 0.7788\n",
      "Epoch 13/20\n",
      "3406/3406 [==============================] - 0s 43us/step - loss: 0.2390 - acc: 0.7610 - auc: 0.8471 - f1: 0.7610 - val_loss: 0.2323 - val_acc: 0.7835 - val_auc: 0.8570 - val_f1: 0.7835\n",
      "Epoch 14/20\n",
      "3406/3406 [==============================] - 0s 43us/step - loss: 0.2350 - acc: 0.7663 - auc: 0.8509 - f1: 0.7663 - val_loss: 0.2289 - val_acc: 0.7894 - val_auc: 0.8639 - val_f1: 0.7894\n",
      "Epoch 15/20\n",
      "3406/3406 [==============================] - 0s 42us/step - loss: 0.2331 - acc: 0.7701 - auc: 0.8532 - f1: 0.7701 - val_loss: 0.2247 - val_acc: 0.7906 - val_auc: 0.8685 - val_f1: 0.7906\n",
      "Epoch 16/20\n",
      "3406/3406 [==============================] - 0s 42us/step - loss: 0.2326 - acc: 0.7728 - auc: 0.8552 - f1: 0.7728 - val_loss: 0.2227 - val_acc: 0.7847 - val_auc: 0.8695 - val_f1: 0.7847\n",
      "Epoch 17/20\n",
      "3406/3406 [==============================] - 0s 45us/step - loss: 0.2285 - acc: 0.7792 - auc: 0.8626 - f1: 0.7792 - val_loss: 0.2224 - val_acc: 0.8000 - val_auc: 0.8709 - val_f1: 0.8000\n",
      "Epoch 18/20\n",
      "3406/3406 [==============================] - 0s 44us/step - loss: 0.2281 - acc: 0.7924 - auc: 0.8610 - f1: 0.7924 - val_loss: 0.2206 - val_acc: 0.7835 - val_auc: 0.8722 - val_f1: 0.7835\n",
      "Epoch 19/20\n",
      "3406/3406 [==============================] - 0s 44us/step - loss: 0.2260 - acc: 0.7824 - auc: 0.8655 - f1: 0.7824 - val_loss: 0.2173 - val_acc: 0.7965 - val_auc: 0.8769 - val_f1: 0.7965\n",
      "Epoch 20/20\n",
      "3406/3406 [==============================] - 0s 43us/step - loss: 0.2202 - acc: 0.7942 - auc: 0.8725 - f1: 0.7942 - val_loss: 0.2179 - val_acc: 0.7871 - val_auc: 0.8759 - val_f1: 0.7871\n",
      "[[279  86]\n",
      " [ 95 390]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.76       365\n",
      "           1       0.82      0.80      0.81       485\n",
      "\n",
      "    accuracy                           0.79       850\n",
      "   macro avg       0.78      0.78      0.78       850\n",
      "weighted avg       0.79      0.79      0.79       850\n",
      "\n",
      "time (in seconds) 28.81954050064087\n",
      "... DONE!\n",
      "... DONE!\n",
      "window_size: 3\n",
      "generating tensor...\n",
      "...DONE!\n",
      "tensor dimensions:\n",
      "tensor input X: (4152, 8, 3)\n",
      "tensor input y: (4152, 2)\n",
      "proportion of y labels: (array([0, 1]), array([1836, 2316]))\n",
      "Splitting dataset into Train and Test sets...\n",
      "Tensor X train: (2906, 3, 8)\n",
      "Tensor y train: (2906, 2)\n",
      "Tensor X test: (1246, 3, 8)\n",
      "Tensor y test: (1246, 2)\n",
      "computing weights...\n",
      "... DONE!\n",
      "setting stratified k-fold...\n",
      "number of k: 5\n",
      "... DONE!\n",
      "Executing algorithm...\n",
      "number of epochs: 20\n",
      "number of batch: 512\n",
      "Training on fold 1/5...\n",
      "model dim:  (3, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_16 (GRU)                 (None, 3, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_17 (GRU)                 (None, 3, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_18 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2324 samples, validate on 582 samples\n",
      "Epoch 1/20\n",
      "2324/2324 [==============================] - 2s 794us/step - loss: 0.3179 - acc: 0.6377 - auc: 0.6905 - f1: 0.6377 - val_loss: 0.2926 - val_acc: 0.7096 - val_auc: 0.7831 - val_f1: 0.7096\n",
      "Epoch 2/20\n",
      "2324/2324 [==============================] - 0s 56us/step - loss: 0.2791 - acc: 0.7186 - auc: 0.7898 - f1: 0.7186 - val_loss: 0.2700 - val_acc: 0.7062 - val_auc: 0.7945 - val_f1: 0.7062\n",
      "Epoch 3/20\n",
      "2324/2324 [==============================] - 0s 59us/step - loss: 0.2736 - acc: 0.7212 - auc: 0.7917 - f1: 0.7212 - val_loss: 0.2708 - val_acc: 0.7079 - val_auc: 0.8017 - val_f1: 0.7079\n",
      "Epoch 4/20\n",
      "2324/2324 [==============================] - 0s 56us/step - loss: 0.2695 - acc: 0.7311 - auc: 0.8003 - f1: 0.7311 - val_loss: 0.2695 - val_acc: 0.7285 - val_auc: 0.8068 - val_f1: 0.7285\n",
      "Epoch 5/20\n",
      "2324/2324 [==============================] - 0s 60us/step - loss: 0.2638 - acc: 0.7388 - auc: 0.8099 - f1: 0.7388 - val_loss: 0.2699 - val_acc: 0.7165 - val_auc: 0.8096 - val_f1: 0.7165\n",
      "Epoch 6/20\n",
      "2324/2324 [==============================] - 0s 58us/step - loss: 0.2633 - acc: 0.7268 - auc: 0.8106 - f1: 0.7268 - val_loss: 0.2637 - val_acc: 0.7234 - val_auc: 0.8076 - val_f1: 0.7234\n",
      "Epoch 7/20\n",
      "2324/2324 [==============================] - 0s 61us/step - loss: 0.2614 - acc: 0.7380 - auc: 0.8127 - f1: 0.7380 - val_loss: 0.2687 - val_acc: 0.7216 - val_auc: 0.8082 - val_f1: 0.7216\n",
      "Epoch 8/20\n",
      "2324/2324 [==============================] - 0s 61us/step - loss: 0.2571 - acc: 0.7298 - auc: 0.8224 - f1: 0.7298 - val_loss: 0.2648 - val_acc: 0.7268 - val_auc: 0.8120 - val_f1: 0.7268\n",
      "Epoch 9/20\n",
      "2324/2324 [==============================] - 0s 60us/step - loss: 0.2582 - acc: 0.7315 - auc: 0.8214 - f1: 0.7315 - val_loss: 0.2609 - val_acc: 0.7182 - val_auc: 0.8183 - val_f1: 0.7182\n",
      "Epoch 10/20\n",
      "2324/2324 [==============================] - 0s 62us/step - loss: 0.2508 - acc: 0.7388 - auc: 0.8299 - f1: 0.7388 - val_loss: 0.2594 - val_acc: 0.7302 - val_auc: 0.8213 - val_f1: 0.7302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "2324/2324 [==============================] - 0s 60us/step - loss: 0.2516 - acc: 0.7496 - auc: 0.8284 - f1: 0.7496 - val_loss: 0.2599 - val_acc: 0.7388 - val_auc: 0.8205 - val_f1: 0.7388\n",
      "Epoch 12/20\n",
      "2324/2324 [==============================] - 0s 60us/step - loss: 0.2486 - acc: 0.7534 - auc: 0.8320 - f1: 0.7534 - val_loss: 0.2592 - val_acc: 0.7285 - val_auc: 0.8235 - val_f1: 0.7285\n",
      "Epoch 13/20\n",
      "2324/2324 [==============================] - 0s 60us/step - loss: 0.2449 - acc: 0.7435 - auc: 0.8370 - f1: 0.7435 - val_loss: 0.2553 - val_acc: 0.7491 - val_auc: 0.8255 - val_f1: 0.7491\n",
      "Epoch 14/20\n",
      "2324/2324 [==============================] - 0s 59us/step - loss: 0.2461 - acc: 0.7500 - auc: 0.8343 - f1: 0.7500 - val_loss: 0.2586 - val_acc: 0.7440 - val_auc: 0.8235 - val_f1: 0.7440\n",
      "Epoch 15/20\n",
      "2324/2324 [==============================] - 0s 60us/step - loss: 0.2425 - acc: 0.7530 - auc: 0.8429 - f1: 0.7530 - val_loss: 0.2546 - val_acc: 0.7457 - val_auc: 0.8286 - val_f1: 0.7457\n",
      "Epoch 16/20\n",
      "2324/2324 [==============================] - 0s 60us/step - loss: 0.2404 - acc: 0.7526 - auc: 0.8443 - f1: 0.7526 - val_loss: 0.2564 - val_acc: 0.7560 - val_auc: 0.8283 - val_f1: 0.7560\n",
      "Epoch 17/20\n",
      "2324/2324 [==============================] - 0s 64us/step - loss: 0.2376 - acc: 0.7664 - auc: 0.8487 - f1: 0.7664 - val_loss: 0.2505 - val_acc: 0.7509 - val_auc: 0.8356 - val_f1: 0.7509\n",
      "Epoch 18/20\n",
      "2324/2324 [==============================] - 0s 61us/step - loss: 0.2372 - acc: 0.7603 - auc: 0.8482 - f1: 0.7603 - val_loss: 0.2508 - val_acc: 0.7577 - val_auc: 0.8375 - val_f1: 0.7577\n",
      "Epoch 19/20\n",
      "2324/2324 [==============================] - 0s 61us/step - loss: 0.2321 - acc: 0.7664 - auc: 0.8561 - f1: 0.7664 - val_loss: 0.2505 - val_acc: 0.7491 - val_auc: 0.8376 - val_f1: 0.7491\n",
      "Epoch 20/20\n",
      "2324/2324 [==============================] - 0s 62us/step - loss: 0.2325 - acc: 0.7664 - auc: 0.8553 - f1: 0.7664 - val_loss: 0.2518 - val_acc: 0.7474 - val_auc: 0.8362 - val_f1: 0.7474\n",
      "[[182  75]\n",
      " [ 72 253]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.71      0.71       257\n",
      "           1       0.77      0.78      0.77       325\n",
      "\n",
      "    accuracy                           0.75       582\n",
      "   macro avg       0.74      0.74      0.74       582\n",
      "weighted avg       0.75      0.75      0.75       582\n",
      "\n",
      "Training on fold 2/5...\n",
      "model dim:  (3, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_19 (GRU)                 (None, 3, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_20 (GRU)                 (None, 3, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_21 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2325 samples, validate on 581 samples\n",
      "Epoch 1/20\n",
      "2325/2325 [==============================] - 2s 887us/step - loss: 0.3220 - acc: 0.5944 - auc: 0.6493 - f1: 0.5944 - val_loss: 0.3008 - val_acc: 0.6919 - val_auc: 0.7607 - val_f1: 0.6919\n",
      "Epoch 2/20\n",
      "2325/2325 [==============================] - 0s 56us/step - loss: 0.2793 - acc: 0.7234 - auc: 0.7898 - f1: 0.7234 - val_loss: 0.2992 - val_acc: 0.6833 - val_auc: 0.7553 - val_f1: 0.6833\n",
      "Epoch 3/20\n",
      "2325/2325 [==============================] - 0s 60us/step - loss: 0.2682 - acc: 0.7316 - auc: 0.8028 - f1: 0.7316 - val_loss: 0.2957 - val_acc: 0.6850 - val_auc: 0.7558 - val_f1: 0.6850\n",
      "Epoch 4/20\n",
      "2325/2325 [==============================] - 0s 62us/step - loss: 0.2583 - acc: 0.7398 - auc: 0.8174 - f1: 0.7398 - val_loss: 0.2935 - val_acc: 0.6954 - val_auc: 0.7690 - val_f1: 0.6954\n",
      "Epoch 5/20\n",
      "2325/2325 [==============================] - 0s 60us/step - loss: 0.2590 - acc: 0.7402 - auc: 0.8180 - f1: 0.7402 - val_loss: 0.2908 - val_acc: 0.6988 - val_auc: 0.7724 - val_f1: 0.6988\n",
      "Epoch 6/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2553 - acc: 0.7381 - auc: 0.8231 - f1: 0.7381 - val_loss: 0.2871 - val_acc: 0.7005 - val_auc: 0.7737 - val_f1: 0.7005\n",
      "Epoch 7/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2533 - acc: 0.7428 - auc: 0.8255 - f1: 0.7428 - val_loss: 0.2876 - val_acc: 0.7040 - val_auc: 0.7741 - val_f1: 0.7040\n",
      "Epoch 8/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2502 - acc: 0.7557 - auc: 0.8309 - f1: 0.7557 - val_loss: 0.2885 - val_acc: 0.7005 - val_auc: 0.7778 - val_f1: 0.7005\n",
      "Epoch 9/20\n",
      "2325/2325 [==============================] - 0s 63us/step - loss: 0.2452 - acc: 0.7561 - auc: 0.8390 - f1: 0.7561 - val_loss: 0.2818 - val_acc: 0.7022 - val_auc: 0.7851 - val_f1: 0.7022\n",
      "Epoch 10/20\n",
      "2325/2325 [==============================] - 0s 59us/step - loss: 0.2453 - acc: 0.7600 - auc: 0.8401 - f1: 0.7600 - val_loss: 0.2821 - val_acc: 0.7091 - val_auc: 0.7845 - val_f1: 0.7091\n",
      "Epoch 11/20\n",
      "2325/2325 [==============================] - 0s 62us/step - loss: 0.2453 - acc: 0.7583 - auc: 0.8376 - f1: 0.7583 - val_loss: 0.2861 - val_acc: 0.7108 - val_auc: 0.7844 - val_f1: 0.7108\n",
      "Epoch 12/20\n",
      "2325/2325 [==============================] - 0s 63us/step - loss: 0.2427 - acc: 0.7566 - auc: 0.8453 - f1: 0.7566 - val_loss: 0.2786 - val_acc: 0.7040 - val_auc: 0.7878 - val_f1: 0.7040\n",
      "Epoch 13/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2376 - acc: 0.7656 - auc: 0.8486 - f1: 0.7656 - val_loss: 0.2801 - val_acc: 0.7005 - val_auc: 0.7894 - val_f1: 0.7005\n",
      "Epoch 14/20\n",
      "2325/2325 [==============================] - 0s 60us/step - loss: 0.2348 - acc: 0.7665 - auc: 0.8533 - f1: 0.7665 - val_loss: 0.2818 - val_acc: 0.7005 - val_auc: 0.7911 - val_f1: 0.7005\n",
      "Epoch 15/20\n",
      "2325/2325 [==============================] - 0s 60us/step - loss: 0.2347 - acc: 0.7613 - auc: 0.8530 - f1: 0.7613 - val_loss: 0.2760 - val_acc: 0.7057 - val_auc: 0.7925 - val_f1: 0.7057\n",
      "Epoch 16/20\n",
      "2325/2325 [==============================] - 0s 63us/step - loss: 0.2319 - acc: 0.7639 - auc: 0.8564 - f1: 0.7639 - val_loss: 0.2727 - val_acc: 0.7108 - val_auc: 0.8007 - val_f1: 0.7108\n",
      "Epoch 17/20\n",
      "2325/2325 [==============================] - 0s 63us/step - loss: 0.2289 - acc: 0.7759 - auc: 0.8597 - f1: 0.7759 - val_loss: 0.2752 - val_acc: 0.7040 - val_auc: 0.7957 - val_f1: 0.7040\n",
      "Epoch 18/20\n",
      "2325/2325 [==============================] - 0s 64us/step - loss: 0.2295 - acc: 0.7725 - auc: 0.8606 - f1: 0.7725 - val_loss: 0.2777 - val_acc: 0.7040 - val_auc: 0.7964 - val_f1: 0.7040\n",
      "Epoch 19/20\n",
      "2325/2325 [==============================] - 0s 62us/step - loss: 0.2259 - acc: 0.7845 - auc: 0.8673 - f1: 0.7845 - val_loss: 0.2731 - val_acc: 0.7143 - val_auc: 0.8030 - val_f1: 0.7143\n",
      "Epoch 20/20\n",
      "2325/2325 [==============================] - 0s 66us/step - loss: 0.2259 - acc: 0.7811 - auc: 0.8663 - f1: 0.7811 - val_loss: 0.2701 - val_acc: 0.7229 - val_auc: 0.8072 - val_f1: 0.7229\n",
      "[[187  70]\n",
      " [ 91 233]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.73      0.70       257\n",
      "           1       0.77      0.72      0.74       324\n",
      "\n",
      "    accuracy                           0.72       581\n",
      "   macro avg       0.72      0.72      0.72       581\n",
      "weighted avg       0.73      0.72      0.72       581\n",
      "\n",
      "Training on fold 3/5...\n",
      "model dim:  (3, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_22 (GRU)                 (None, 3, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_23 (GRU)                 (None, 3, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_24 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2325 samples, validate on 581 samples\n",
      "Epoch 1/20\n",
      "2325/2325 [==============================] - 2s 981us/step - loss: 0.3190 - acc: 0.6237 - auc: 0.6734 - f1: 0.6237 - val_loss: 0.2658 - val_acc: 0.7487 - val_auc: 0.8118 - val_f1: 0.7487\n",
      "Epoch 2/20\n",
      "2325/2325 [==============================] - 0s 55us/step - loss: 0.2861 - acc: 0.7067 - auc: 0.7748 - f1: 0.7067 - val_loss: 0.2562 - val_acc: 0.7349 - val_auc: 0.8251 - val_f1: 0.7349\n",
      "Epoch 3/20\n",
      "2325/2325 [==============================] - 0s 60us/step - loss: 0.2759 - acc: 0.7170 - auc: 0.7858 - f1: 0.7170 - val_loss: 0.2554 - val_acc: 0.7349 - val_auc: 0.8258 - val_f1: 0.7349\n",
      "Epoch 4/20\n",
      "2325/2325 [==============================] - 0s 59us/step - loss: 0.2744 - acc: 0.7101 - auc: 0.7911 - f1: 0.7101 - val_loss: 0.2503 - val_acc: 0.7694 - val_auc: 0.8320 - val_f1: 0.7694\n",
      "Epoch 5/20\n",
      "2325/2325 [==============================] - 0s 60us/step - loss: 0.2710 - acc: 0.7239 - auc: 0.7986 - f1: 0.7239 - val_loss: 0.2486 - val_acc: 0.7539 - val_auc: 0.8346 - val_f1: 0.7539\n",
      "Epoch 6/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2670 - acc: 0.7252 - auc: 0.8035 - f1: 0.7252 - val_loss: 0.2454 - val_acc: 0.7590 - val_auc: 0.8388 - val_f1: 0.7590\n",
      "Epoch 7/20\n",
      "2325/2325 [==============================] - 0s 59us/step - loss: 0.2612 - acc: 0.7230 - auc: 0.8114 - f1: 0.7230 - val_loss: 0.2458 - val_acc: 0.7504 - val_auc: 0.8411 - val_f1: 0.7504\n",
      "Epoch 8/20\n",
      "2325/2325 [==============================] - 0s 60us/step - loss: 0.2588 - acc: 0.7351 - auc: 0.8178 - f1: 0.7351 - val_loss: 0.2419 - val_acc: 0.7608 - val_auc: 0.8430 - val_f1: 0.7608\n",
      "Epoch 9/20\n",
      "2325/2325 [==============================] - 0s 60us/step - loss: 0.2554 - acc: 0.7333 - auc: 0.8216 - f1: 0.7333 - val_loss: 0.2422 - val_acc: 0.7539 - val_auc: 0.8430 - val_f1: 0.7539\n",
      "Epoch 10/20\n",
      "2325/2325 [==============================] - 0s 60us/step - loss: 0.2523 - acc: 0.7454 - auc: 0.8269 - f1: 0.7454 - val_loss: 0.2409 - val_acc: 0.7522 - val_auc: 0.8437 - val_f1: 0.7522\n",
      "Epoch 11/20\n",
      "2325/2325 [==============================] - 0s 63us/step - loss: 0.2511 - acc: 0.7432 - auc: 0.8272 - f1: 0.7432 - val_loss: 0.2404 - val_acc: 0.7573 - val_auc: 0.8438 - val_f1: 0.7573\n",
      "Epoch 12/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2507 - acc: 0.7389 - auc: 0.8296 - f1: 0.7389 - val_loss: 0.2412 - val_acc: 0.7522 - val_auc: 0.8452 - val_f1: 0.7522\n",
      "Epoch 13/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2480 - acc: 0.7389 - auc: 0.8339 - f1: 0.7389 - val_loss: 0.2398 - val_acc: 0.7556 - val_auc: 0.8452 - val_f1: 0.7556\n",
      "Epoch 14/20\n",
      "2325/2325 [==============================] - 0s 63us/step - loss: 0.2491 - acc: 0.7557 - auc: 0.8367 - f1: 0.7557 - val_loss: 0.2525 - val_acc: 0.7332 - val_auc: 0.8441 - val_f1: 0.7332\n",
      "Epoch 15/20\n",
      "2325/2325 [==============================] - 0s 63us/step - loss: 0.2504 - acc: 0.7419 - auc: 0.8349 - f1: 0.7419 - val_loss: 0.2425 - val_acc: 0.7573 - val_auc: 0.8410 - val_f1: 0.7573\n",
      "Epoch 16/20\n",
      "2325/2325 [==============================] - 0s 63us/step - loss: 0.2447 - acc: 0.7570 - auc: 0.8423 - f1: 0.7570 - val_loss: 0.2393 - val_acc: 0.7522 - val_auc: 0.8453 - val_f1: 0.7522\n",
      "Epoch 17/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2414 - acc: 0.7591 - auc: 0.8431 - f1: 0.7591 - val_loss: 0.2399 - val_acc: 0.7487 - val_auc: 0.8475 - val_f1: 0.7487\n",
      "Epoch 18/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2406 - acc: 0.7523 - auc: 0.8455 - f1: 0.7523 - val_loss: 0.2366 - val_acc: 0.7642 - val_auc: 0.8500 - val_f1: 0.7642\n",
      "Epoch 19/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2393 - acc: 0.7574 - auc: 0.8471 - f1: 0.7574 - val_loss: 0.2393 - val_acc: 0.7608 - val_auc: 0.8505 - val_f1: 0.7608\n",
      "Epoch 20/20\n",
      "2325/2325 [==============================] - 0s 62us/step - loss: 0.2332 - acc: 0.7699 - auc: 0.8559 - f1: 0.7699 - val_loss: 0.2378 - val_acc: 0.7642 - val_auc: 0.8500 - val_f1: 0.7642\n",
      "[[196  61]\n",
      " [ 76 248]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.76      0.74       257\n",
      "           1       0.80      0.77      0.78       324\n",
      "\n",
      "    accuracy                           0.76       581\n",
      "   macro avg       0.76      0.76      0.76       581\n",
      "weighted avg       0.77      0.76      0.76       581\n",
      "\n",
      "Training on fold 4/5...\n",
      "model dim:  (3, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_25 (GRU)                 (None, 3, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_26 (GRU)                 (None, 3, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_27 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2325 samples, validate on 581 samples\n",
      "Epoch 1/20\n",
      "2325/2325 [==============================] - 2s 1ms/step - loss: 0.3290 - acc: 0.5880 - auc: 0.6521 - f1: 0.5880 - val_loss: 0.3153 - val_acc: 0.6850 - val_auc: 0.7408 - val_f1: 0.6850\n",
      "Epoch 2/20\n",
      "2325/2325 [==============================] - 0s 56us/step - loss: 0.2864 - acc: 0.7123 - auc: 0.7742 - f1: 0.7123 - val_loss: 0.2788 - val_acc: 0.7143 - val_auc: 0.7869 - val_f1: 0.7143\n",
      "Epoch 3/20\n",
      "2325/2325 [==============================] - 0s 59us/step - loss: 0.2757 - acc: 0.7183 - auc: 0.7891 - f1: 0.7183 - val_loss: 0.2705 - val_acc: 0.7263 - val_auc: 0.7988 - val_f1: 0.7263\n",
      "Epoch 4/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2719 - acc: 0.7161 - auc: 0.7945 - f1: 0.7161 - val_loss: 0.2689 - val_acc: 0.7194 - val_auc: 0.8001 - val_f1: 0.7194\n",
      "Epoch 5/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2661 - acc: 0.7226 - auc: 0.8040 - f1: 0.7226 - val_loss: 0.2751 - val_acc: 0.7091 - val_auc: 0.7945 - val_f1: 0.7091\n",
      "Epoch 6/20\n",
      "2325/2325 [==============================] - 0s 60us/step - loss: 0.2616 - acc: 0.7303 - auc: 0.8121 - f1: 0.7303 - val_loss: 0.2699 - val_acc: 0.7263 - val_auc: 0.7990 - val_f1: 0.7263\n",
      "Epoch 7/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2608 - acc: 0.7342 - auc: 0.8127 - f1: 0.7342 - val_loss: 0.2661 - val_acc: 0.7298 - val_auc: 0.8048 - val_f1: 0.7298\n",
      "Epoch 8/20\n",
      "2325/2325 [==============================] - 0s 60us/step - loss: 0.2580 - acc: 0.7359 - auc: 0.8175 - f1: 0.7359 - val_loss: 0.2653 - val_acc: 0.7298 - val_auc: 0.8072 - val_f1: 0.7298\n",
      "Epoch 9/20\n",
      "2325/2325 [==============================] - 0s 60us/step - loss: 0.2547 - acc: 0.7389 - auc: 0.8230 - f1: 0.7389 - val_loss: 0.2659 - val_acc: 0.7367 - val_auc: 0.8076 - val_f1: 0.7367\n",
      "Epoch 10/20\n",
      "2325/2325 [==============================] - 0s 62us/step - loss: 0.2526 - acc: 0.7394 - auc: 0.8254 - f1: 0.7394 - val_loss: 0.2649 - val_acc: 0.7384 - val_auc: 0.8083 - val_f1: 0.7384\n",
      "Epoch 11/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2487 - acc: 0.7454 - auc: 0.8351 - f1: 0.7454 - val_loss: 0.2679 - val_acc: 0.7298 - val_auc: 0.8118 - val_f1: 0.7298\n",
      "Epoch 12/20\n",
      "2325/2325 [==============================] - 0s 63us/step - loss: 0.2503 - acc: 0.7462 - auc: 0.8309 - f1: 0.7462 - val_loss: 0.2637 - val_acc: 0.7470 - val_auc: 0.8135 - val_f1: 0.7470\n",
      "Epoch 13/20\n",
      "2325/2325 [==============================] - 0s 62us/step - loss: 0.2450 - acc: 0.7480 - auc: 0.8388 - f1: 0.7480 - val_loss: 0.2671 - val_acc: 0.7367 - val_auc: 0.8132 - val_f1: 0.7367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2466 - acc: 0.7531 - auc: 0.8350 - f1: 0.7531 - val_loss: 0.2663 - val_acc: 0.7418 - val_auc: 0.8147 - val_f1: 0.7418\n",
      "Epoch 15/20\n",
      "2325/2325 [==============================] - 0s 62us/step - loss: 0.2440 - acc: 0.7458 - auc: 0.8409 - f1: 0.7458 - val_loss: 0.2695 - val_acc: 0.7367 - val_auc: 0.8120 - val_f1: 0.7367\n",
      "Epoch 16/20\n",
      "2325/2325 [==============================] - 0s 62us/step - loss: 0.2405 - acc: 0.7617 - auc: 0.8461 - f1: 0.7617 - val_loss: 0.2609 - val_acc: 0.7573 - val_auc: 0.8163 - val_f1: 0.7573\n",
      "Epoch 17/20\n",
      "2325/2325 [==============================] - 0s 62us/step - loss: 0.2381 - acc: 0.7617 - auc: 0.8480 - f1: 0.7617 - val_loss: 0.2712 - val_acc: 0.7263 - val_auc: 0.8093 - val_f1: 0.7263\n",
      "Epoch 18/20\n",
      "2325/2325 [==============================] - 0s 63us/step - loss: 0.2377 - acc: 0.7548 - auc: 0.8521 - f1: 0.7548 - val_loss: 0.2628 - val_acc: 0.7453 - val_auc: 0.8150 - val_f1: 0.7453\n",
      "Epoch 19/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2349 - acc: 0.7720 - auc: 0.8542 - f1: 0.7720 - val_loss: 0.2591 - val_acc: 0.7435 - val_auc: 0.8193 - val_f1: 0.7435\n",
      "Epoch 20/20\n",
      "2325/2325 [==============================] - 0s 62us/step - loss: 0.2310 - acc: 0.7652 - auc: 0.8591 - f1: 0.7652 - val_loss: 0.2668 - val_acc: 0.7384 - val_auc: 0.8144 - val_f1: 0.7384\n",
      "[[185  72]\n",
      " [ 80 244]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71       257\n",
      "           1       0.77      0.75      0.76       324\n",
      "\n",
      "    accuracy                           0.74       581\n",
      "   macro avg       0.74      0.74      0.74       581\n",
      "weighted avg       0.74      0.74      0.74       581\n",
      "\n",
      "Training on fold 5/5...\n",
      "model dim:  (3, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_28 (GRU)                 (None, 3, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_29 (GRU)                 (None, 3, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_30 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2325 samples, validate on 581 samples\n",
      "Epoch 1/20\n",
      "2325/2325 [==============================] - 3s 1ms/step - loss: 0.3263 - acc: 0.6082 - auc: 0.6594 - f1: 0.6082 - val_loss: 0.2714 - val_acc: 0.7453 - val_auc: 0.8045 - val_f1: 0.7453\n",
      "Epoch 2/20\n",
      "2325/2325 [==============================] - 0s 57us/step - loss: 0.2846 - acc: 0.7196 - auc: 0.7805 - f1: 0.7196 - val_loss: 0.2538 - val_acc: 0.7573 - val_auc: 0.8287 - val_f1: 0.7573\n",
      "Epoch 3/20\n",
      "2325/2325 [==============================] - 0s 58us/step - loss: 0.2774 - acc: 0.7153 - auc: 0.7855 - f1: 0.7153 - val_loss: 0.2500 - val_acc: 0.7435 - val_auc: 0.8356 - val_f1: 0.7435\n",
      "Epoch 4/20\n",
      "2325/2325 [==============================] - 0s 60us/step - loss: 0.2727 - acc: 0.7213 - auc: 0.7926 - f1: 0.7213 - val_loss: 0.2486 - val_acc: 0.7590 - val_auc: 0.8336 - val_f1: 0.7590\n",
      "Epoch 5/20\n",
      "2325/2325 [==============================] - 0s 59us/step - loss: 0.2664 - acc: 0.7333 - auc: 0.8039 - f1: 0.7333 - val_loss: 0.2496 - val_acc: 0.7418 - val_auc: 0.8325 - val_f1: 0.7418\n",
      "Epoch 6/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2637 - acc: 0.7252 - auc: 0.8075 - f1: 0.7252 - val_loss: 0.2487 - val_acc: 0.7487 - val_auc: 0.8337 - val_f1: 0.7487\n",
      "Epoch 7/20\n",
      "2325/2325 [==============================] - 0s 59us/step - loss: 0.2624 - acc: 0.7312 - auc: 0.8108 - f1: 0.7312 - val_loss: 0.2476 - val_acc: 0.7470 - val_auc: 0.8349 - val_f1: 0.7470\n",
      "Epoch 8/20\n",
      "2325/2325 [==============================] - 0s 62us/step - loss: 0.2570 - acc: 0.7355 - auc: 0.8188 - f1: 0.7355 - val_loss: 0.2473 - val_acc: 0.7470 - val_auc: 0.8331 - val_f1: 0.7470\n",
      "Epoch 9/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2579 - acc: 0.7406 - auc: 0.8160 - f1: 0.7406 - val_loss: 0.2480 - val_acc: 0.7522 - val_auc: 0.8323 - val_f1: 0.7522\n",
      "Epoch 10/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2520 - acc: 0.7406 - auc: 0.8255 - f1: 0.7406 - val_loss: 0.2483 - val_acc: 0.7522 - val_auc: 0.8324 - val_f1: 0.7522\n",
      "Epoch 11/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2503 - acc: 0.7454 - auc: 0.8292 - f1: 0.7454 - val_loss: 0.2491 - val_acc: 0.7367 - val_auc: 0.8301 - val_f1: 0.7367\n",
      "Epoch 12/20\n",
      "2325/2325 [==============================] - 0s 62us/step - loss: 0.2507 - acc: 0.7437 - auc: 0.8313 - f1: 0.7437 - val_loss: 0.2490 - val_acc: 0.7349 - val_auc: 0.8300 - val_f1: 0.7349\n",
      "Epoch 13/20\n",
      "2325/2325 [==============================] - 0s 62us/step - loss: 0.2490 - acc: 0.7514 - auc: 0.8320 - f1: 0.7514 - val_loss: 0.2512 - val_acc: 0.7453 - val_auc: 0.8316 - val_f1: 0.7453\n",
      "Epoch 14/20\n",
      "2325/2325 [==============================] - 0s 62us/step - loss: 0.2389 - acc: 0.7553 - auc: 0.8468 - f1: 0.7553 - val_loss: 0.2530 - val_acc: 0.7349 - val_auc: 0.8299 - val_f1: 0.7349\n",
      "Epoch 15/20\n",
      "2325/2325 [==============================] - 0s 60us/step - loss: 0.2458 - acc: 0.7561 - auc: 0.8387 - f1: 0.7561 - val_loss: 0.2497 - val_acc: 0.7281 - val_auc: 0.8304 - val_f1: 0.7281\n",
      "Epoch 16/20\n",
      "2325/2325 [==============================] - 0s 62us/step - loss: 0.2396 - acc: 0.7630 - auc: 0.8463 - f1: 0.7630 - val_loss: 0.2482 - val_acc: 0.7367 - val_auc: 0.8332 - val_f1: 0.7367\n",
      "Epoch 17/20\n",
      "2325/2325 [==============================] - 0s 61us/step - loss: 0.2436 - acc: 0.7488 - auc: 0.8429 - f1: 0.7488 - val_loss: 0.2531 - val_acc: 0.7263 - val_auc: 0.8336 - val_f1: 0.7263\n",
      "Epoch 18/20\n",
      "2325/2325 [==============================] - 0s 62us/step - loss: 0.2411 - acc: 0.7501 - auc: 0.8462 - f1: 0.7501 - val_loss: 0.2491 - val_acc: 0.7281 - val_auc: 0.8298 - val_f1: 0.7281\n",
      "Epoch 19/20\n",
      "2325/2325 [==============================] - 0s 62us/step - loss: 0.2360 - acc: 0.7716 - auc: 0.8542 - f1: 0.7716 - val_loss: 0.2472 - val_acc: 0.7281 - val_auc: 0.8356 - val_f1: 0.7281\n",
      "Epoch 20/20\n",
      "2325/2325 [==============================] - 0s 63us/step - loss: 0.2339 - acc: 0.7733 - auc: 0.8556 - f1: 0.7733 - val_loss: 0.2542 - val_acc: 0.7401 - val_auc: 0.8361 - val_f1: 0.7401\n",
      "[[164  93]\n",
      " [ 58 266]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.64      0.68       257\n",
      "           1       0.74      0.82      0.78       324\n",
      "\n",
      "    accuracy                           0.74       581\n",
      "   macro avg       0.74      0.73      0.73       581\n",
      "weighted avg       0.74      0.74      0.74       581\n",
      "\n",
      "time (in seconds) 35.42365837097168\n",
      "... DONE!\n",
      "... DONE!\n",
      "window_size: 4\n",
      "generating tensor...\n",
      "...DONE!\n",
      "tensor dimensions:\n",
      "tensor input X: (2650, 8, 4)\n",
      "tensor input y: (2650, 2)\n",
      "proportion of y labels: (array([0, 1]), array([1310, 1340]))\n",
      "Splitting dataset into Train and Test sets...\n",
      "Tensor X train: (1855, 4, 8)\n",
      "Tensor y train: (1855, 2)\n",
      "Tensor X test: (795, 4, 8)\n",
      "Tensor y test: (795, 2)\n",
      "computing weights...\n",
      "... DONE!\n",
      "setting stratified k-fold...\n",
      "number of k: 5\n",
      "... DONE!\n",
      "Executing algorithm...\n",
      "number of epochs: 20\n",
      "number of batch: 512\n",
      "Training on fold 1/5...\n",
      "model dim:  (4, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_31 (GRU)                 (None, 4, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_32 (GRU)                 (None, 4, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_33 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1483 samples, validate on 372 samples\n",
      "Epoch 1/20\n",
      "1483/1483 [==============================] - 3s 2ms/step - loss: 0.3312 - acc: 0.6102 - auc: 0.6739 - f1: 0.6102 - val_loss: 0.3318 - val_acc: 0.6774 - val_auc: 0.7214 - val_f1: 0.6774\n",
      "Epoch 2/20\n",
      "1483/1483 [==============================] - 0s 69us/step - loss: 0.2995 - acc: 0.7013 - auc: 0.7695 - f1: 0.7013 - val_loss: 0.3192 - val_acc: 0.6882 - val_auc: 0.7397 - val_f1: 0.6882\n",
      "Epoch 3/20\n",
      "1483/1483 [==============================] - 0s 71us/step - loss: 0.2840 - acc: 0.7020 - auc: 0.7818 - f1: 0.7020 - val_loss: 0.3010 - val_acc: 0.6747 - val_auc: 0.7478 - val_f1: 0.6747\n",
      "Epoch 4/20\n",
      "1483/1483 [==============================] - 0s 74us/step - loss: 0.2791 - acc: 0.7215 - auc: 0.7900 - f1: 0.7215 - val_loss: 0.2985 - val_acc: 0.6909 - val_auc: 0.7499 - val_f1: 0.6909\n",
      "Epoch 5/20\n",
      "1483/1483 [==============================] - 0s 75us/step - loss: 0.2801 - acc: 0.7141 - auc: 0.7896 - f1: 0.7141 - val_loss: 0.3048 - val_acc: 0.6989 - val_auc: 0.7529 - val_f1: 0.6989\n",
      "Epoch 6/20\n",
      "1483/1483 [==============================] - 0s 74us/step - loss: 0.2741 - acc: 0.7242 - auc: 0.7976 - f1: 0.7242 - val_loss: 0.3037 - val_acc: 0.7097 - val_auc: 0.7529 - val_f1: 0.7097\n",
      "Epoch 7/20\n",
      "1483/1483 [==============================] - 0s 77us/step - loss: 0.2790 - acc: 0.7229 - auc: 0.7914 - f1: 0.7229 - val_loss: 0.3036 - val_acc: 0.6962 - val_auc: 0.7566 - val_f1: 0.6962\n",
      "Epoch 8/20\n",
      "1483/1483 [==============================] - 0s 75us/step - loss: 0.2705 - acc: 0.7249 - auc: 0.8041 - f1: 0.7249 - val_loss: 0.3012 - val_acc: 0.7151 - val_auc: 0.7617 - val_f1: 0.7151\n",
      "Epoch 9/20\n",
      "1483/1483 [==============================] - 0s 75us/step - loss: 0.2732 - acc: 0.7222 - auc: 0.8002 - f1: 0.7222 - val_loss: 0.2916 - val_acc: 0.7204 - val_auc: 0.7667 - val_f1: 0.7204\n",
      "Epoch 10/20\n",
      "1483/1483 [==============================] - 0s 76us/step - loss: 0.2614 - acc: 0.7451 - auc: 0.8219 - f1: 0.7451 - val_loss: 0.2868 - val_acc: 0.6801 - val_auc: 0.7706 - val_f1: 0.6801\n",
      "Epoch 11/20\n",
      "1483/1483 [==============================] - 0s 76us/step - loss: 0.2619 - acc: 0.7384 - auc: 0.8189 - f1: 0.7384 - val_loss: 0.2867 - val_acc: 0.7070 - val_auc: 0.7748 - val_f1: 0.7070\n",
      "Epoch 12/20\n",
      "1483/1483 [==============================] - 0s 76us/step - loss: 0.2587 - acc: 0.7444 - auc: 0.8241 - f1: 0.7444 - val_loss: 0.2876 - val_acc: 0.6935 - val_auc: 0.7757 - val_f1: 0.6935\n",
      "Epoch 13/20\n",
      "1483/1483 [==============================] - 0s 77us/step - loss: 0.2559 - acc: 0.7384 - auc: 0.8245 - f1: 0.7384 - val_loss: 0.2878 - val_acc: 0.6935 - val_auc: 0.7765 - val_f1: 0.6935\n",
      "Epoch 14/20\n",
      "1483/1483 [==============================] - 0s 79us/step - loss: 0.2596 - acc: 0.7404 - auc: 0.8226 - f1: 0.7404 - val_loss: 0.2870 - val_acc: 0.7070 - val_auc: 0.7784 - val_f1: 0.7070\n",
      "Epoch 15/20\n",
      "1483/1483 [==============================] - 0s 75us/step - loss: 0.2531 - acc: 0.7546 - auc: 0.8307 - f1: 0.7546 - val_loss: 0.2865 - val_acc: 0.6935 - val_auc: 0.7815 - val_f1: 0.6935\n",
      "Epoch 16/20\n",
      "1483/1483 [==============================] - 0s 76us/step - loss: 0.2516 - acc: 0.7498 - auc: 0.8347 - f1: 0.7498 - val_loss: 0.2861 - val_acc: 0.7151 - val_auc: 0.7823 - val_f1: 0.7151\n",
      "Epoch 17/20\n",
      "1483/1483 [==============================] - 0s 76us/step - loss: 0.2539 - acc: 0.7471 - auc: 0.8310 - f1: 0.7471 - val_loss: 0.2868 - val_acc: 0.7016 - val_auc: 0.7806 - val_f1: 0.7016\n",
      "Epoch 18/20\n",
      "1483/1483 [==============================] - 0s 77us/step - loss: 0.2493 - acc: 0.7620 - auc: 0.8375 - f1: 0.7620 - val_loss: 0.2848 - val_acc: 0.6909 - val_auc: 0.7812 - val_f1: 0.6909\n",
      "Epoch 19/20\n",
      "1483/1483 [==============================] - 0s 76us/step - loss: 0.2529 - acc: 0.7566 - auc: 0.8332 - f1: 0.7566 - val_loss: 0.2866 - val_acc: 0.7097 - val_auc: 0.7840 - val_f1: 0.7097\n",
      "Epoch 20/20\n",
      "1483/1483 [==============================] - 0s 79us/step - loss: 0.2423 - acc: 0.7633 - auc: 0.8454 - f1: 0.7633 - val_loss: 0.2864 - val_acc: 0.7097 - val_auc: 0.7832 - val_f1: 0.7097\n",
      "[[125  59]\n",
      " [ 49 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.68      0.70       184\n",
      "           1       0.70      0.74      0.72       188\n",
      "\n",
      "    accuracy                           0.71       372\n",
      "   macro avg       0.71      0.71      0.71       372\n",
      "weighted avg       0.71      0.71      0.71       372\n",
      "\n",
      "Training on fold 2/5...\n",
      "model dim:  (4, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_34 (GRU)                 (None, 4, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_35 (GRU)                 (None, 4, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_36 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1483 samples, validate on 372 samples\n",
      "Epoch 1/20\n",
      "1483/1483 [==============================] - 3s 2ms/step - loss: 0.3556 - acc: 0.5806 - auc: 0.6335 - f1: 0.5806 - val_loss: 0.2983 - val_acc: 0.6828 - val_auc: 0.7544 - val_f1: 0.6828\n",
      "Epoch 2/20\n",
      "1483/1483 [==============================] - 0s 69us/step - loss: 0.3086 - acc: 0.6811 - auc: 0.7471 - f1: 0.6811 - val_loss: 0.3078 - val_acc: 0.6828 - val_auc: 0.7748 - val_f1: 0.6828\n",
      "Epoch 3/20\n",
      "1483/1483 [==============================] - 0s 72us/step - loss: 0.2943 - acc: 0.6878 - auc: 0.7721 - f1: 0.6878 - val_loss: 0.2843 - val_acc: 0.7177 - val_auc: 0.7814 - val_f1: 0.7177\n",
      "Epoch 4/20\n",
      "1483/1483 [==============================] - 0s 74us/step - loss: 0.2845 - acc: 0.7013 - auc: 0.7848 - f1: 0.7013 - val_loss: 0.2820 - val_acc: 0.7231 - val_auc: 0.7846 - val_f1: 0.7231\n",
      "Epoch 5/20\n",
      "1483/1483 [==============================] - 0s 77us/step - loss: 0.2804 - acc: 0.7114 - auc: 0.7837 - f1: 0.7114 - val_loss: 0.2885 - val_acc: 0.7151 - val_auc: 0.7879 - val_f1: 0.7151\n",
      "Epoch 6/20\n",
      "1483/1483 [==============================] - 0s 75us/step - loss: 0.2787 - acc: 0.7148 - auc: 0.7923 - f1: 0.7148 - val_loss: 0.2801 - val_acc: 0.7151 - val_auc: 0.7927 - val_f1: 0.7151\n",
      "Epoch 7/20\n",
      "1483/1483 [==============================] - 0s 77us/step - loss: 0.2764 - acc: 0.7222 - auc: 0.7910 - f1: 0.7222 - val_loss: 0.2760 - val_acc: 0.7312 - val_auc: 0.7953 - val_f1: 0.7312\n",
      "Epoch 8/20\n",
      "1483/1483 [==============================] - 0s 75us/step - loss: 0.2743 - acc: 0.7168 - auc: 0.7990 - f1: 0.7168 - val_loss: 0.2746 - val_acc: 0.7285 - val_auc: 0.7981 - val_f1: 0.7285\n",
      "Epoch 9/20\n",
      "1483/1483 [==============================] - 0s 77us/step - loss: 0.2694 - acc: 0.7222 - auc: 0.8047 - f1: 0.7222 - val_loss: 0.2773 - val_acc: 0.7151 - val_auc: 0.8013 - val_f1: 0.7151\n",
      "Epoch 10/20\n",
      "1483/1483 [==============================] - 0s 80us/step - loss: 0.2696 - acc: 0.7323 - auc: 0.8062 - f1: 0.7323 - val_loss: 0.2726 - val_acc: 0.7151 - val_auc: 0.8047 - val_f1: 0.7151\n",
      "Epoch 11/20\n",
      "1483/1483 [==============================] - 0s 78us/step - loss: 0.2629 - acc: 0.7363 - auc: 0.8180 - f1: 0.7363 - val_loss: 0.2703 - val_acc: 0.7285 - val_auc: 0.8041 - val_f1: 0.7285\n",
      "Epoch 12/20\n",
      "1483/1483 [==============================] - 0s 79us/step - loss: 0.2649 - acc: 0.7370 - auc: 0.8138 - f1: 0.7370 - val_loss: 0.2702 - val_acc: 0.7258 - val_auc: 0.8078 - val_f1: 0.7258\n",
      "Epoch 13/20\n",
      "1483/1483 [==============================] - 0s 79us/step - loss: 0.2613 - acc: 0.7370 - auc: 0.8170 - f1: 0.7370 - val_loss: 0.2718 - val_acc: 0.7151 - val_auc: 0.8096 - val_f1: 0.7151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "1483/1483 [==============================] - 0s 75us/step - loss: 0.2567 - acc: 0.7444 - auc: 0.8249 - f1: 0.7444 - val_loss: 0.2706 - val_acc: 0.7339 - val_auc: 0.8099 - val_f1: 0.7339\n",
      "Epoch 15/20\n",
      "1483/1483 [==============================] - 0s 76us/step - loss: 0.2558 - acc: 0.7343 - auc: 0.8236 - f1: 0.7343 - val_loss: 0.2691 - val_acc: 0.7473 - val_auc: 0.8108 - val_f1: 0.7473\n",
      "Epoch 16/20\n",
      "1483/1483 [==============================] - 0s 79us/step - loss: 0.2556 - acc: 0.7411 - auc: 0.8261 - f1: 0.7411 - val_loss: 0.2693 - val_acc: 0.7366 - val_auc: 0.8123 - val_f1: 0.7366\n",
      "Epoch 17/20\n",
      "1483/1483 [==============================] - 0s 80us/step - loss: 0.2505 - acc: 0.7532 - auc: 0.8335 - f1: 0.7532 - val_loss: 0.2711 - val_acc: 0.7366 - val_auc: 0.8139 - val_f1: 0.7366\n",
      "Epoch 18/20\n",
      "1483/1483 [==============================] - 0s 78us/step - loss: 0.2499 - acc: 0.7404 - auc: 0.8347 - f1: 0.7404 - val_loss: 0.2689 - val_acc: 0.7312 - val_auc: 0.8137 - val_f1: 0.7312\n",
      "Epoch 19/20\n",
      "1483/1483 [==============================] - 0s 77us/step - loss: 0.2451 - acc: 0.7505 - auc: 0.8402 - f1: 0.7505 - val_loss: 0.2709 - val_acc: 0.7312 - val_auc: 0.8126 - val_f1: 0.7312\n",
      "Epoch 20/20\n",
      "1483/1483 [==============================] - 0s 77us/step - loss: 0.2475 - acc: 0.7593 - auc: 0.8402 - f1: 0.7593 - val_loss: 0.2736 - val_acc: 0.7339 - val_auc: 0.8141 - val_f1: 0.7339\n",
      "[[145  39]\n",
      " [ 60 128]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.79      0.75       184\n",
      "           1       0.77      0.68      0.72       188\n",
      "\n",
      "    accuracy                           0.73       372\n",
      "   macro avg       0.74      0.73      0.73       372\n",
      "weighted avg       0.74      0.73      0.73       372\n",
      "\n",
      "Training on fold 3/5...\n",
      "model dim:  (4, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_37 (GRU)                 (None, 4, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_38 (GRU)                 (None, 4, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_39 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1484 samples, validate on 371 samples\n",
      "Epoch 1/20\n",
      "1484/1484 [==============================] - 3s 2ms/step - loss: 0.3670 - acc: 0.5512 - auc: 0.5862 - f1: 0.5512 - val_loss: 0.3010 - val_acc: 0.7089 - val_auc: 0.7704 - val_f1: 0.7089\n",
      "Epoch 2/20\n",
      "1484/1484 [==============================] - 0s 69us/step - loss: 0.3133 - acc: 0.6786 - auc: 0.7469 - f1: 0.6786 - val_loss: 0.2955 - val_acc: 0.7197 - val_auc: 0.7843 - val_f1: 0.7197\n",
      "Epoch 3/20\n",
      "1484/1484 [==============================] - 0s 74us/step - loss: 0.2991 - acc: 0.7042 - auc: 0.7673 - f1: 0.7042 - val_loss: 0.2729 - val_acc: 0.7278 - val_auc: 0.8035 - val_f1: 0.7278\n",
      "Epoch 4/20\n",
      "1484/1484 [==============================] - 0s 73us/step - loss: 0.2897 - acc: 0.7123 - auc: 0.7700 - f1: 0.7123 - val_loss: 0.2745 - val_acc: 0.7224 - val_auc: 0.8047 - val_f1: 0.7224\n",
      "Epoch 5/20\n",
      "1484/1484 [==============================] - 0s 73us/step - loss: 0.2918 - acc: 0.7049 - auc: 0.7645 - f1: 0.7049 - val_loss: 0.2715 - val_acc: 0.7278 - val_auc: 0.8054 - val_f1: 0.7278\n",
      "Epoch 6/20\n",
      "1484/1484 [==============================] - 0s 75us/step - loss: 0.2922 - acc: 0.6907 - auc: 0.7650 - f1: 0.6907 - val_loss: 0.2685 - val_acc: 0.7385 - val_auc: 0.8084 - val_f1: 0.7385\n",
      "Epoch 7/20\n",
      "1484/1484 [==============================] - 0s 76us/step - loss: 0.2824 - acc: 0.7082 - auc: 0.7848 - f1: 0.7082 - val_loss: 0.2690 - val_acc: 0.7197 - val_auc: 0.8095 - val_f1: 0.7197\n",
      "Epoch 8/20\n",
      "1484/1484 [==============================] - 0s 76us/step - loss: 0.2851 - acc: 0.7082 - auc: 0.7828 - f1: 0.7082 - val_loss: 0.2693 - val_acc: 0.7143 - val_auc: 0.8107 - val_f1: 0.7143\n",
      "Epoch 9/20\n",
      "1484/1484 [==============================] - 0s 75us/step - loss: 0.2696 - acc: 0.7190 - auc: 0.8042 - f1: 0.7190 - val_loss: 0.2634 - val_acc: 0.7358 - val_auc: 0.8144 - val_f1: 0.7358\n",
      "Epoch 10/20\n",
      "1484/1484 [==============================] - 0s 75us/step - loss: 0.2747 - acc: 0.7163 - auc: 0.7989 - f1: 0.7163 - val_loss: 0.2612 - val_acc: 0.7278 - val_auc: 0.8156 - val_f1: 0.7278\n",
      "Epoch 11/20\n",
      "1484/1484 [==============================] - 0s 77us/step - loss: 0.2715 - acc: 0.7278 - auc: 0.8026 - f1: 0.7278 - val_loss: 0.2647 - val_acc: 0.7251 - val_auc: 0.8143 - val_f1: 0.7251\n",
      "Epoch 12/20\n",
      "1484/1484 [==============================] - 0s 75us/step - loss: 0.2680 - acc: 0.7392 - auc: 0.8095 - f1: 0.7392 - val_loss: 0.2627 - val_acc: 0.7439 - val_auc: 0.8137 - val_f1: 0.7439\n",
      "Epoch 13/20\n",
      "1484/1484 [==============================] - 0s 78us/step - loss: 0.2658 - acc: 0.7264 - auc: 0.8143 - f1: 0.7264 - val_loss: 0.2640 - val_acc: 0.7412 - val_auc: 0.8134 - val_f1: 0.7412\n",
      "Epoch 14/20\n",
      "1484/1484 [==============================] - 0s 81us/step - loss: 0.2595 - acc: 0.7426 - auc: 0.8196 - f1: 0.7426 - val_loss: 0.2664 - val_acc: 0.7358 - val_auc: 0.8134 - val_f1: 0.7358\n",
      "Epoch 15/20\n",
      "1484/1484 [==============================] - 0s 76us/step - loss: 0.2641 - acc: 0.7332 - auc: 0.8153 - f1: 0.7332 - val_loss: 0.2646 - val_acc: 0.7385 - val_auc: 0.8151 - val_f1: 0.7385\n",
      "Epoch 16/20\n",
      "1484/1484 [==============================] - 0s 82us/step - loss: 0.2583 - acc: 0.7311 - auc: 0.8240 - f1: 0.7311 - val_loss: 0.2642 - val_acc: 0.7278 - val_auc: 0.8153 - val_f1: 0.7278\n",
      "Epoch 17/20\n",
      "1484/1484 [==============================] - 0s 79us/step - loss: 0.2572 - acc: 0.7446 - auc: 0.8265 - f1: 0.7446 - val_loss: 0.2659 - val_acc: 0.7385 - val_auc: 0.8119 - val_f1: 0.7385\n",
      "Epoch 18/20\n",
      "1484/1484 [==============================] - 0s 77us/step - loss: 0.2543 - acc: 0.7473 - auc: 0.8298 - f1: 0.7473 - val_loss: 0.2647 - val_acc: 0.7251 - val_auc: 0.8135 - val_f1: 0.7251\n",
      "Epoch 19/20\n",
      "1484/1484 [==============================] - 0s 80us/step - loss: 0.2541 - acc: 0.7426 - auc: 0.8298 - f1: 0.7426 - val_loss: 0.2685 - val_acc: 0.7358 - val_auc: 0.8112 - val_f1: 0.7358\n",
      "Epoch 20/20\n",
      "1484/1484 [==============================] - 0s 80us/step - loss: 0.2464 - acc: 0.7567 - auc: 0.8423 - f1: 0.7567 - val_loss: 0.2708 - val_acc: 0.7412 - val_auc: 0.8103 - val_f1: 0.7412\n",
      "[[125  58]\n",
      " [ 38 150]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.68      0.72       183\n",
      "           1       0.72      0.80      0.76       188\n",
      "\n",
      "    accuracy                           0.74       371\n",
      "   macro avg       0.74      0.74      0.74       371\n",
      "weighted avg       0.74      0.74      0.74       371\n",
      "\n",
      "Training on fold 4/5...\n",
      "model dim:  (4, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_40 (GRU)                 (None, 4, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_41 (GRU)                 (None, 4, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_42 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1485 samples, validate on 370 samples\n",
      "Epoch 1/20\n",
      "1485/1485 [==============================] - 4s 2ms/step - loss: 0.3633 - acc: 0.5495 - auc: 0.6184 - f1: 0.5495 - val_loss: 0.3098 - val_acc: 0.6838 - val_auc: 0.7522 - val_f1: 0.6838\n",
      "Epoch 2/20\n",
      "1485/1485 [==============================] - 0s 70us/step - loss: 0.3118 - acc: 0.6842 - auc: 0.7407 - f1: 0.6842 - val_loss: 0.3037 - val_acc: 0.7027 - val_auc: 0.7658 - val_f1: 0.7027\n",
      "Epoch 3/20\n",
      "1485/1485 [==============================] - 0s 72us/step - loss: 0.3036 - acc: 0.6923 - auc: 0.7552 - f1: 0.6923 - val_loss: 0.2893 - val_acc: 0.6973 - val_auc: 0.7781 - val_f1: 0.6973\n",
      "Epoch 4/20\n",
      "1485/1485 [==============================] - 0s 75us/step - loss: 0.2932 - acc: 0.7104 - auc: 0.7637 - f1: 0.7104 - val_loss: 0.2859 - val_acc: 0.6973 - val_auc: 0.7797 - val_f1: 0.6973\n",
      "Epoch 5/20\n",
      "1485/1485 [==============================] - 0s 75us/step - loss: 0.2832 - acc: 0.7199 - auc: 0.7816 - f1: 0.7199 - val_loss: 0.2805 - val_acc: 0.7054 - val_auc: 0.7846 - val_f1: 0.7054\n",
      "Epoch 6/20\n",
      "1485/1485 [==============================] - 0s 75us/step - loss: 0.2829 - acc: 0.7104 - auc: 0.7797 - f1: 0.7104 - val_loss: 0.2785 - val_acc: 0.7135 - val_auc: 0.7906 - val_f1: 0.7135\n",
      "Epoch 7/20\n",
      "1485/1485 [==============================] - 0s 74us/step - loss: 0.2710 - acc: 0.7239 - auc: 0.8004 - f1: 0.7239 - val_loss: 0.2805 - val_acc: 0.7135 - val_auc: 0.7923 - val_f1: 0.7135\n",
      "Epoch 8/20\n",
      "1485/1485 [==============================] - 0s 74us/step - loss: 0.2747 - acc: 0.7232 - auc: 0.7962 - f1: 0.7232 - val_loss: 0.2810 - val_acc: 0.7081 - val_auc: 0.7909 - val_f1: 0.7081\n",
      "Epoch 9/20\n",
      "1485/1485 [==============================] - 0s 75us/step - loss: 0.2644 - acc: 0.7448 - auc: 0.8129 - f1: 0.7448 - val_loss: 0.2801 - val_acc: 0.7108 - val_auc: 0.7889 - val_f1: 0.7108\n",
      "Epoch 10/20\n",
      "1485/1485 [==============================] - 0s 77us/step - loss: 0.2643 - acc: 0.7367 - auc: 0.8143 - f1: 0.7367 - val_loss: 0.2803 - val_acc: 0.7189 - val_auc: 0.7888 - val_f1: 0.7189\n",
      "Epoch 11/20\n",
      "1485/1485 [==============================] - 0s 76us/step - loss: 0.2658 - acc: 0.7340 - auc: 0.8112 - f1: 0.7340 - val_loss: 0.2797 - val_acc: 0.7000 - val_auc: 0.7868 - val_f1: 0.7000\n",
      "Epoch 12/20\n",
      "1485/1485 [==============================] - 0s 77us/step - loss: 0.2596 - acc: 0.7360 - auc: 0.8207 - f1: 0.7360 - val_loss: 0.2825 - val_acc: 0.7054 - val_auc: 0.7874 - val_f1: 0.7054\n",
      "Epoch 13/20\n",
      "1485/1485 [==============================] - 0s 77us/step - loss: 0.2601 - acc: 0.7354 - auc: 0.8195 - f1: 0.7354 - val_loss: 0.2844 - val_acc: 0.7162 - val_auc: 0.7872 - val_f1: 0.7162\n",
      "Epoch 14/20\n",
      "1485/1485 [==============================] - 0s 76us/step - loss: 0.2559 - acc: 0.7441 - auc: 0.8264 - f1: 0.7441 - val_loss: 0.2847 - val_acc: 0.7108 - val_auc: 0.7880 - val_f1: 0.7108\n",
      "Epoch 15/20\n",
      "1485/1485 [==============================] - 0s 81us/step - loss: 0.2545 - acc: 0.7434 - auc: 0.8299 - f1: 0.7434 - val_loss: 0.2893 - val_acc: 0.7216 - val_auc: 0.7889 - val_f1: 0.7216\n",
      "Epoch 16/20\n",
      "1485/1485 [==============================] - 0s 76us/step - loss: 0.2607 - acc: 0.7340 - auc: 0.8204 - f1: 0.7340 - val_loss: 0.2858 - val_acc: 0.7027 - val_auc: 0.7863 - val_f1: 0.7027\n",
      "Epoch 17/20\n",
      "1485/1485 [==============================] - 0s 79us/step - loss: 0.2470 - acc: 0.7576 - auc: 0.8405 - f1: 0.7576 - val_loss: 0.2916 - val_acc: 0.7081 - val_auc: 0.7862 - val_f1: 0.7081\n",
      "Epoch 18/20\n",
      "1485/1485 [==============================] - 0s 78us/step - loss: 0.2509 - acc: 0.7488 - auc: 0.8354 - f1: 0.7488 - val_loss: 0.2883 - val_acc: 0.6946 - val_auc: 0.7839 - val_f1: 0.6946\n",
      "Epoch 19/20\n",
      "1485/1485 [==============================] - 0s 78us/step - loss: 0.2455 - acc: 0.7515 - auc: 0.8424 - f1: 0.7515 - val_loss: 0.2904 - val_acc: 0.7108 - val_auc: 0.7878 - val_f1: 0.7108\n",
      "Epoch 20/20\n",
      "1485/1485 [==============================] - 0s 76us/step - loss: 0.2463 - acc: 0.7529 - auc: 0.8444 - f1: 0.7529 - val_loss: 0.2943 - val_acc: 0.7162 - val_auc: 0.7870 - val_f1: 0.7162\n",
      "[[138  45]\n",
      " [ 60 127]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72       183\n",
      "           1       0.74      0.68      0.71       187\n",
      "\n",
      "    accuracy                           0.72       370\n",
      "   macro avg       0.72      0.72      0.72       370\n",
      "weighted avg       0.72      0.72      0.72       370\n",
      "\n",
      "Training on fold 5/5...\n",
      "model dim:  (4, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_43 (GRU)                 (None, 4, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_44 (GRU)                 (None, 4, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_45 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1485 samples, validate on 370 samples\n",
      "Epoch 1/20\n",
      "1485/1485 [==============================] - 4s 3ms/step - loss: 0.3474 - acc: 0.5636 - auc: 0.6263 - f1: 0.5636 - val_loss: 0.2854 - val_acc: 0.7027 - val_auc: 0.7812 - val_f1: 0.7027\n",
      "Epoch 2/20\n",
      "1485/1485 [==============================] - 0s 70us/step - loss: 0.3058 - acc: 0.6923 - auc: 0.7495 - f1: 0.6923 - val_loss: 0.2809 - val_acc: 0.7135 - val_auc: 0.7974 - val_f1: 0.7135\n",
      "Epoch 3/20\n",
      "1485/1485 [==============================] - 0s 74us/step - loss: 0.2939 - acc: 0.7024 - auc: 0.7707 - f1: 0.7024 - val_loss: 0.2718 - val_acc: 0.7297 - val_auc: 0.8071 - val_f1: 0.7297\n",
      "Epoch 4/20\n",
      "1485/1485 [==============================] - 0s 72us/step - loss: 0.2883 - acc: 0.7071 - auc: 0.7738 - f1: 0.7071 - val_loss: 0.2689 - val_acc: 0.7432 - val_auc: 0.8055 - val_f1: 0.7432\n",
      "Epoch 5/20\n",
      "1485/1485 [==============================] - 0s 73us/step - loss: 0.2863 - acc: 0.7104 - auc: 0.7734 - f1: 0.7104 - val_loss: 0.2711 - val_acc: 0.7351 - val_auc: 0.8055 - val_f1: 0.7351\n",
      "Epoch 6/20\n",
      "1485/1485 [==============================] - 0s 74us/step - loss: 0.2845 - acc: 0.7152 - auc: 0.7762 - f1: 0.7152 - val_loss: 0.2646 - val_acc: 0.7243 - val_auc: 0.8122 - val_f1: 0.7243\n",
      "Epoch 7/20\n",
      "1485/1485 [==============================] - 0s 78us/step - loss: 0.2804 - acc: 0.7118 - auc: 0.7854 - f1: 0.7118 - val_loss: 0.2626 - val_acc: 0.7432 - val_auc: 0.8160 - val_f1: 0.7432\n",
      "Epoch 8/20\n",
      "1485/1485 [==============================] - 0s 76us/step - loss: 0.2783 - acc: 0.7152 - auc: 0.7915 - f1: 0.7152 - val_loss: 0.2617 - val_acc: 0.7432 - val_auc: 0.8186 - val_f1: 0.7432\n",
      "Epoch 9/20\n",
      "1485/1485 [==============================] - 0s 76us/step - loss: 0.2685 - acc: 0.7279 - auc: 0.8070 - f1: 0.7279 - val_loss: 0.2586 - val_acc: 0.7459 - val_auc: 0.8224 - val_f1: 0.7459\n",
      "Epoch 10/20\n",
      "1485/1485 [==============================] - 0s 74us/step - loss: 0.2690 - acc: 0.7320 - auc: 0.8052 - f1: 0.7320 - val_loss: 0.2565 - val_acc: 0.7432 - val_auc: 0.8252 - val_f1: 0.7432\n",
      "Epoch 11/20\n",
      "1485/1485 [==============================] - 0s 76us/step - loss: 0.2661 - acc: 0.7360 - auc: 0.8097 - f1: 0.7360 - val_loss: 0.2571 - val_acc: 0.7432 - val_auc: 0.8236 - val_f1: 0.7432\n",
      "Epoch 12/20\n",
      "1485/1485 [==============================] - 0s 77us/step - loss: 0.2619 - acc: 0.7475 - auc: 0.8154 - f1: 0.7475 - val_loss: 0.2578 - val_acc: 0.7432 - val_auc: 0.8216 - val_f1: 0.7432\n",
      "Epoch 13/20\n",
      "1485/1485 [==============================] - 0s 79us/step - loss: 0.2585 - acc: 0.7414 - auc: 0.8224 - f1: 0.7414 - val_loss: 0.2592 - val_acc: 0.7541 - val_auc: 0.8225 - val_f1: 0.7541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "1485/1485 [==============================] - 0s 79us/step - loss: 0.2545 - acc: 0.7468 - auc: 0.8282 - f1: 0.7468 - val_loss: 0.2633 - val_acc: 0.7297 - val_auc: 0.8199 - val_f1: 0.7297\n",
      "Epoch 15/20\n",
      "1485/1485 [==============================] - 0s 76us/step - loss: 0.2518 - acc: 0.7535 - auc: 0.8330 - f1: 0.7535 - val_loss: 0.2632 - val_acc: 0.7270 - val_auc: 0.8174 - val_f1: 0.7270\n",
      "Epoch 16/20\n",
      "1485/1485 [==============================] - 0s 76us/step - loss: 0.2534 - acc: 0.7495 - auc: 0.8352 - f1: 0.7495 - val_loss: 0.2653 - val_acc: 0.7189 - val_auc: 0.8121 - val_f1: 0.7189\n",
      "Epoch 17/20\n",
      "1485/1485 [==============================] - 0s 79us/step - loss: 0.2556 - acc: 0.7434 - auc: 0.8309 - f1: 0.7434 - val_loss: 0.2643 - val_acc: 0.7243 - val_auc: 0.8153 - val_f1: 0.7243\n",
      "Epoch 18/20\n",
      "1485/1485 [==============================] - 0s 78us/step - loss: 0.2490 - acc: 0.7549 - auc: 0.8412 - f1: 0.7549 - val_loss: 0.2666 - val_acc: 0.7378 - val_auc: 0.8153 - val_f1: 0.7378\n",
      "Epoch 19/20\n",
      "1485/1485 [==============================] - 0s 77us/step - loss: 0.2489 - acc: 0.7508 - auc: 0.8420 - f1: 0.7508 - val_loss: 0.2679 - val_acc: 0.7297 - val_auc: 0.8119 - val_f1: 0.7297\n",
      "Epoch 20/20\n",
      "1485/1485 [==============================] - 0s 76us/step - loss: 0.2454 - acc: 0.7495 - auc: 0.8434 - f1: 0.7495 - val_loss: 0.2692 - val_acc: 0.7000 - val_auc: 0.8096 - val_f1: 0.7000\n",
      "[[140  43]\n",
      " [ 68 119]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.77      0.72       183\n",
      "           1       0.73      0.64      0.68       187\n",
      "\n",
      "    accuracy                           0.70       370\n",
      "   macro avg       0.70      0.70      0.70       370\n",
      "weighted avg       0.70      0.70      0.70       370\n",
      "\n",
      "time (in seconds) 39.789008140563965\n",
      "... DONE!\n",
      "... DONE!\n",
      "window_size: 5\n",
      "generating tensor...\n",
      "...DONE!\n",
      "tensor dimensions:\n",
      "tensor input X: (1523, 8, 5)\n",
      "tensor input y: (1523, 2)\n",
      "proportion of y labels: (array([0, 1]), array([794, 729]))\n",
      "Splitting dataset into Train and Test sets...\n",
      "Tensor X train: (1066, 5, 8)\n",
      "Tensor y train: (1066, 2)\n",
      "Tensor X test: (457, 5, 8)\n",
      "Tensor y test: (457, 2)\n",
      "computing weights...\n",
      "... DONE!\n",
      "setting stratified k-fold...\n",
      "number of k: 5\n",
      "... DONE!\n",
      "Executing algorithm...\n",
      "number of epochs: 20\n",
      "number of batch: 512\n",
      "Training on fold 1/5...\n",
      "model dim:  (5, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_46 (GRU)                 (None, 5, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_47 (GRU)                 (None, 5, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_48 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 852 samples, validate on 214 samples\n",
      "Epoch 1/20\n",
      "852/852 [==============================] - 4s 5ms/step - loss: 0.3625 - acc: 0.5305 - auc: 0.5452 - f1: 0.5305 - val_loss: 0.3132 - val_acc: 0.7009 - val_auc: 0.7414 - val_f1: 0.7009\n",
      "Epoch 2/20\n",
      "852/852 [==============================] - 0s 93us/step - loss: 0.3223 - acc: 0.6667 - auc: 0.7336 - f1: 0.6667 - val_loss: 0.3337 - val_acc: 0.6682 - val_auc: 0.7543 - val_f1: 0.6682\n",
      "Epoch 3/20\n",
      "852/852 [==============================] - 0s 86us/step - loss: 0.3065 - acc: 0.6761 - auc: 0.7561 - f1: 0.6761 - val_loss: 0.2943 - val_acc: 0.6963 - val_auc: 0.7782 - val_f1: 0.6963\n",
      "Epoch 4/20\n",
      "852/852 [==============================] - 0s 91us/step - loss: 0.2925 - acc: 0.6937 - auc: 0.7608 - f1: 0.6937 - val_loss: 0.2737 - val_acc: 0.7243 - val_auc: 0.7911 - val_f1: 0.7243\n",
      "Epoch 5/20\n",
      "852/852 [==============================] - 0s 96us/step - loss: 0.2940 - acc: 0.7007 - auc: 0.7582 - f1: 0.7007 - val_loss: 0.2745 - val_acc: 0.7196 - val_auc: 0.7902 - val_f1: 0.7196\n",
      "Epoch 6/20\n",
      "852/852 [==============================] - 0s 97us/step - loss: 0.2864 - acc: 0.6890 - auc: 0.7716 - f1: 0.6890 - val_loss: 0.2799 - val_acc: 0.6963 - val_auc: 0.7887 - val_f1: 0.6963\n",
      "Epoch 7/20\n",
      "852/852 [==============================] - 0s 97us/step - loss: 0.2756 - acc: 0.7336 - auc: 0.7943 - f1: 0.7336 - val_loss: 0.2816 - val_acc: 0.6963 - val_auc: 0.7866 - val_f1: 0.6963\n",
      "Epoch 8/20\n",
      "852/852 [==============================] - 0s 94us/step - loss: 0.2698 - acc: 0.7195 - auc: 0.7992 - f1: 0.7195 - val_loss: 0.2820 - val_acc: 0.7150 - val_auc: 0.7876 - val_f1: 0.7150\n",
      "Epoch 9/20\n",
      "852/852 [==============================] - 0s 93us/step - loss: 0.2665 - acc: 0.7171 - auc: 0.8059 - f1: 0.7171 - val_loss: 0.2848 - val_acc: 0.7150 - val_auc: 0.7871 - val_f1: 0.7150\n",
      "Epoch 10/20\n",
      "852/852 [==============================] - 0s 97us/step - loss: 0.2712 - acc: 0.7265 - auc: 0.8005 - f1: 0.7265 - val_loss: 0.2886 - val_acc: 0.7056 - val_auc: 0.7834 - val_f1: 0.7056\n",
      "Epoch 11/20\n",
      "852/852 [==============================] - 0s 98us/step - loss: 0.2668 - acc: 0.7207 - auc: 0.8081 - f1: 0.7207 - val_loss: 0.2910 - val_acc: 0.6963 - val_auc: 0.7792 - val_f1: 0.6963\n",
      "Epoch 12/20\n",
      "852/852 [==============================] - 0s 102us/step - loss: 0.2514 - acc: 0.7347 - auc: 0.8306 - f1: 0.7347 - val_loss: 0.2869 - val_acc: 0.7196 - val_auc: 0.7762 - val_f1: 0.7196\n",
      "Epoch 13/20\n",
      "852/852 [==============================] - 0s 100us/step - loss: 0.2556 - acc: 0.7336 - auc: 0.8236 - f1: 0.7336 - val_loss: 0.2851 - val_acc: 0.7383 - val_auc: 0.7750 - val_f1: 0.7383\n",
      "Epoch 14/20\n",
      "852/852 [==============================] - 0s 100us/step - loss: 0.2571 - acc: 0.7359 - auc: 0.8250 - f1: 0.7359 - val_loss: 0.2874 - val_acc: 0.7290 - val_auc: 0.7753 - val_f1: 0.7290\n",
      "Epoch 15/20\n",
      "852/852 [==============================] - 0s 98us/step - loss: 0.2536 - acc: 0.7512 - auc: 0.8274 - f1: 0.7512 - val_loss: 0.2898 - val_acc: 0.7150 - val_auc: 0.7781 - val_f1: 0.7150\n",
      "Epoch 16/20\n",
      "852/852 [==============================] - 0s 95us/step - loss: 0.2534 - acc: 0.7430 - auc: 0.8253 - f1: 0.7430 - val_loss: 0.2920 - val_acc: 0.7150 - val_auc: 0.7802 - val_f1: 0.7150\n",
      "Epoch 17/20\n",
      "852/852 [==============================] - 0s 98us/step - loss: 0.2426 - acc: 0.7594 - auc: 0.8457 - f1: 0.7594 - val_loss: 0.2967 - val_acc: 0.7103 - val_auc: 0.7726 - val_f1: 0.7103\n",
      "Epoch 18/20\n",
      "852/852 [==============================] - 0s 97us/step - loss: 0.2444 - acc: 0.7430 - auc: 0.8392 - f1: 0.7430 - val_loss: 0.2919 - val_acc: 0.7150 - val_auc: 0.7735 - val_f1: 0.7150\n",
      "Epoch 19/20\n",
      "852/852 [==============================] - 0s 101us/step - loss: 0.2378 - acc: 0.7653 - auc: 0.8528 - f1: 0.7653 - val_loss: 0.2958 - val_acc: 0.7009 - val_auc: 0.7629 - val_f1: 0.7009\n",
      "Epoch 20/20\n",
      "852/852 [==============================] - 0s 97us/step - loss: 0.2346 - acc: 0.7570 - auc: 0.8534 - f1: 0.7570 - val_loss: 0.3001 - val_acc: 0.6776 - val_auc: 0.7613 - val_f1: 0.6776\n",
      "[[69 44]\n",
      " [25 76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.61      0.67       113\n",
      "           1       0.63      0.75      0.69       101\n",
      "\n",
      "    accuracy                           0.68       214\n",
      "   macro avg       0.68      0.68      0.68       214\n",
      "weighted avg       0.69      0.68      0.68       214\n",
      "\n",
      "Training on fold 2/5...\n",
      "model dim:  (5, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_49 (GRU)                 (None, 5, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_50 (GRU)                 (None, 5, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_51 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 852 samples, validate on 214 samples\n",
      "Epoch 1/20\n",
      "852/852 [==============================] - 5s 5ms/step - loss: 0.3492 - acc: 0.5634 - auc: 0.5691 - f1: 0.5634 - val_loss: 0.3080 - val_acc: 0.6636 - val_auc: 0.7407 - val_f1: 0.6636\n",
      "Epoch 2/20\n",
      "852/852 [==============================] - 0s 89us/step - loss: 0.3175 - acc: 0.6643 - auc: 0.7323 - f1: 0.6643 - val_loss: 0.3116 - val_acc: 0.6869 - val_auc: 0.7590 - val_f1: 0.6869\n",
      "Epoch 3/20\n",
      "852/852 [==============================] - 0s 88us/step - loss: 0.3082 - acc: 0.6819 - auc: 0.7450 - f1: 0.6819 - val_loss: 0.2881 - val_acc: 0.6869 - val_auc: 0.7741 - val_f1: 0.6869\n",
      "Epoch 4/20\n",
      "852/852 [==============================] - 0s 93us/step - loss: 0.2916 - acc: 0.6901 - auc: 0.7664 - f1: 0.6901 - val_loss: 0.2811 - val_acc: 0.6869 - val_auc: 0.7821 - val_f1: 0.6869\n",
      "Epoch 5/20\n",
      "852/852 [==============================] - 0s 93us/step - loss: 0.2828 - acc: 0.7077 - auc: 0.7764 - f1: 0.7077 - val_loss: 0.2803 - val_acc: 0.7103 - val_auc: 0.7853 - val_f1: 0.7103\n",
      "Epoch 6/20\n",
      "852/852 [==============================] - 0s 96us/step - loss: 0.2867 - acc: 0.6948 - auc: 0.7677 - f1: 0.6948 - val_loss: 0.2784 - val_acc: 0.7103 - val_auc: 0.7837 - val_f1: 0.7103\n",
      "Epoch 7/20\n",
      "852/852 [==============================] - 0s 98us/step - loss: 0.2865 - acc: 0.7077 - auc: 0.7705 - f1: 0.7077 - val_loss: 0.2774 - val_acc: 0.7009 - val_auc: 0.7804 - val_f1: 0.7009\n",
      "Epoch 8/20\n",
      "852/852 [==============================] - 0s 98us/step - loss: 0.2758 - acc: 0.7101 - auc: 0.7884 - f1: 0.7101 - val_loss: 0.2805 - val_acc: 0.7009 - val_auc: 0.7845 - val_f1: 0.7009\n",
      "Epoch 9/20\n",
      "852/852 [==============================] - 0s 97us/step - loss: 0.2752 - acc: 0.7007 - auc: 0.7889 - f1: 0.7007 - val_loss: 0.2776 - val_acc: 0.7056 - val_auc: 0.7867 - val_f1: 0.7056\n",
      "Epoch 10/20\n",
      "852/852 [==============================] - 0s 97us/step - loss: 0.2712 - acc: 0.7101 - auc: 0.7946 - f1: 0.7101 - val_loss: 0.2756 - val_acc: 0.6869 - val_auc: 0.7861 - val_f1: 0.6869\n",
      "Epoch 11/20\n",
      "852/852 [==============================] - 0s 99us/step - loss: 0.2712 - acc: 0.7101 - auc: 0.7965 - f1: 0.7101 - val_loss: 0.2758 - val_acc: 0.6963 - val_auc: 0.7877 - val_f1: 0.6963\n",
      "Epoch 12/20\n",
      "852/852 [==============================] - 0s 97us/step - loss: 0.2687 - acc: 0.7101 - auc: 0.7984 - f1: 0.7101 - val_loss: 0.2774 - val_acc: 0.6916 - val_auc: 0.7896 - val_f1: 0.6916\n",
      "Epoch 13/20\n",
      "852/852 [==============================] - 0s 105us/step - loss: 0.2638 - acc: 0.7218 - auc: 0.8096 - f1: 0.7218 - val_loss: 0.2755 - val_acc: 0.6869 - val_auc: 0.7916 - val_f1: 0.6869\n",
      "Epoch 14/20\n",
      "852/852 [==============================] - 0s 98us/step - loss: 0.2632 - acc: 0.7300 - auc: 0.8123 - f1: 0.7300 - val_loss: 0.2735 - val_acc: 0.7103 - val_auc: 0.7908 - val_f1: 0.7103\n",
      "Epoch 15/20\n",
      "852/852 [==============================] - 0s 96us/step - loss: 0.2552 - acc: 0.7312 - auc: 0.8243 - f1: 0.7312 - val_loss: 0.2718 - val_acc: 0.6916 - val_auc: 0.7913 - val_f1: 0.6916\n",
      "Epoch 16/20\n",
      "852/852 [==============================] - 0s 102us/step - loss: 0.2503 - acc: 0.7383 - auc: 0.8307 - f1: 0.7383 - val_loss: 0.2709 - val_acc: 0.6822 - val_auc: 0.7924 - val_f1: 0.6822\n",
      "Epoch 17/20\n",
      "852/852 [==============================] - 0s 103us/step - loss: 0.2504 - acc: 0.7371 - auc: 0.8290 - f1: 0.7371 - val_loss: 0.2745 - val_acc: 0.6682 - val_auc: 0.7931 - val_f1: 0.6682\n",
      "Epoch 18/20\n",
      "852/852 [==============================] - 0s 101us/step - loss: 0.2455 - acc: 0.7477 - auc: 0.8381 - f1: 0.7477 - val_loss: 0.2724 - val_acc: 0.6682 - val_auc: 0.7926 - val_f1: 0.6682\n",
      "Epoch 19/20\n",
      "852/852 [==============================] - 0s 100us/step - loss: 0.2478 - acc: 0.7394 - auc: 0.8327 - f1: 0.7394 - val_loss: 0.2701 - val_acc: 0.6589 - val_auc: 0.7909 - val_f1: 0.6589\n",
      "Epoch 20/20\n",
      "852/852 [==============================] - 0s 100us/step - loss: 0.2425 - acc: 0.7594 - auc: 0.8430 - f1: 0.7594 - val_loss: 0.2708 - val_acc: 0.6822 - val_auc: 0.7909 - val_f1: 0.6822\n",
      "[[78 35]\n",
      " [33 68]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.69      0.70       113\n",
      "           1       0.66      0.67      0.67       101\n",
      "\n",
      "    accuracy                           0.68       214\n",
      "   macro avg       0.68      0.68      0.68       214\n",
      "weighted avg       0.68      0.68      0.68       214\n",
      "\n",
      "Training on fold 3/5...\n",
      "model dim:  (5, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_52 (GRU)                 (None, 5, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_53 (GRU)                 (None, 5, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_54 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 853 samples, validate on 213 samples\n",
      "Epoch 1/20\n",
      "853/853 [==============================] - 4s 5ms/step - loss: 0.3378 - acc: 0.5932 - auc: 0.6344 - f1: 0.5932 - val_loss: 0.3051 - val_acc: 0.6761 - val_auc: 0.7500 - val_f1: 0.6761\n",
      "Epoch 2/20\n",
      "853/853 [==============================] - 0s 97us/step - loss: 0.3220 - acc: 0.6624 - auc: 0.7302 - f1: 0.6624 - val_loss: 0.2870 - val_acc: 0.6901 - val_auc: 0.7738 - val_f1: 0.6901\n",
      "Epoch 3/20\n",
      "853/853 [==============================] - 0s 93us/step - loss: 0.2983 - acc: 0.6905 - auc: 0.7512 - f1: 0.6905 - val_loss: 0.2937 - val_acc: 0.7089 - val_auc: 0.7810 - val_f1: 0.7089\n",
      "Epoch 4/20\n",
      "853/853 [==============================] - 0s 95us/step - loss: 0.2941 - acc: 0.6928 - auc: 0.7610 - f1: 0.6928 - val_loss: 0.2834 - val_acc: 0.7230 - val_auc: 0.7876 - val_f1: 0.7230\n",
      "Epoch 5/20\n",
      "853/853 [==============================] - 0s 92us/step - loss: 0.2899 - acc: 0.7093 - auc: 0.7618 - f1: 0.7093 - val_loss: 0.2763 - val_acc: 0.7559 - val_auc: 0.7909 - val_f1: 0.7559\n",
      "Epoch 6/20\n",
      "853/853 [==============================] - 0s 94us/step - loss: 0.2891 - acc: 0.7128 - auc: 0.7685 - f1: 0.7128 - val_loss: 0.2743 - val_acc: 0.7465 - val_auc: 0.7927 - val_f1: 0.7465\n",
      "Epoch 7/20\n",
      "853/853 [==============================] - 0s 94us/step - loss: 0.2839 - acc: 0.7128 - auc: 0.7769 - f1: 0.7128 - val_loss: 0.2740 - val_acc: 0.7418 - val_auc: 0.7983 - val_f1: 0.7418\n",
      "Epoch 8/20\n",
      "853/853 [==============================] - 0s 96us/step - loss: 0.2772 - acc: 0.7245 - auc: 0.7904 - f1: 0.7245 - val_loss: 0.2720 - val_acc: 0.7418 - val_auc: 0.8038 - val_f1: 0.7418\n",
      "Epoch 9/20\n",
      "853/853 [==============================] - 0s 94us/step - loss: 0.2745 - acc: 0.7233 - auc: 0.7934 - f1: 0.7233 - val_loss: 0.2653 - val_acc: 0.7277 - val_auc: 0.8090 - val_f1: 0.7277\n",
      "Epoch 10/20\n",
      "853/853 [==============================] - 0s 93us/step - loss: 0.2685 - acc: 0.7257 - auc: 0.8046 - f1: 0.7257 - val_loss: 0.2597 - val_acc: 0.7324 - val_auc: 0.8159 - val_f1: 0.7324\n",
      "Epoch 11/20\n",
      "853/853 [==============================] - 0s 100us/step - loss: 0.2677 - acc: 0.7444 - auc: 0.8056 - f1: 0.7444 - val_loss: 0.2589 - val_acc: 0.7230 - val_auc: 0.8185 - val_f1: 0.7230\n",
      "Epoch 12/20\n",
      "853/853 [==============================] - 0s 102us/step - loss: 0.2651 - acc: 0.7304 - auc: 0.8150 - f1: 0.7304 - val_loss: 0.2571 - val_acc: 0.7230 - val_auc: 0.8227 - val_f1: 0.7230\n",
      "Epoch 13/20\n",
      "853/853 [==============================] - 0s 97us/step - loss: 0.2614 - acc: 0.7128 - auc: 0.8133 - f1: 0.7128 - val_loss: 0.2556 - val_acc: 0.7418 - val_auc: 0.8219 - val_f1: 0.7418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "853/853 [==============================] - 0s 97us/step - loss: 0.2609 - acc: 0.7491 - auc: 0.8176 - f1: 0.7491 - val_loss: 0.2573 - val_acc: 0.7512 - val_auc: 0.8178 - val_f1: 0.7512\n",
      "Epoch 15/20\n",
      "853/853 [==============================] - 0s 101us/step - loss: 0.2586 - acc: 0.7304 - auc: 0.8209 - f1: 0.7304 - val_loss: 0.2582 - val_acc: 0.7512 - val_auc: 0.8205 - val_f1: 0.7512\n",
      "Epoch 16/20\n",
      "853/853 [==============================] - 0s 98us/step - loss: 0.2571 - acc: 0.7433 - auc: 0.8247 - f1: 0.7433 - val_loss: 0.2543 - val_acc: 0.7183 - val_auc: 0.8255 - val_f1: 0.7183\n",
      "Epoch 17/20\n",
      "853/853 [==============================] - 0s 98us/step - loss: 0.2558 - acc: 0.7386 - auc: 0.8240 - f1: 0.7386 - val_loss: 0.2528 - val_acc: 0.7136 - val_auc: 0.8269 - val_f1: 0.7136\n",
      "Epoch 18/20\n",
      "853/853 [==============================] - 0s 98us/step - loss: 0.2538 - acc: 0.7433 - auc: 0.8260 - f1: 0.7433 - val_loss: 0.2606 - val_acc: 0.7183 - val_auc: 0.8238 - val_f1: 0.7183\n",
      "Epoch 19/20\n",
      "853/853 [==============================] - 0s 96us/step - loss: 0.2474 - acc: 0.7468 - auc: 0.8375 - f1: 0.7468 - val_loss: 0.2648 - val_acc: 0.7183 - val_auc: 0.8182 - val_f1: 0.7183\n",
      "Epoch 20/20\n",
      "853/853 [==============================] - 0s 98us/step - loss: 0.2486 - acc: 0.7538 - auc: 0.8362 - f1: 0.7538 - val_loss: 0.2579 - val_acc: 0.7230 - val_auc: 0.8207 - val_f1: 0.7230\n",
      "[[80 32]\n",
      " [27 74]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.71      0.73       112\n",
      "           1       0.70      0.73      0.71       101\n",
      "\n",
      "    accuracy                           0.72       213\n",
      "   macro avg       0.72      0.72      0.72       213\n",
      "weighted avg       0.72      0.72      0.72       213\n",
      "\n",
      "Training on fold 4/5...\n",
      "model dim:  (5, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_55 (GRU)                 (None, 5, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_56 (GRU)                 (None, 5, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_57 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 853 samples, validate on 213 samples\n",
      "Epoch 1/20\n",
      "853/853 [==============================] - 5s 5ms/step - loss: 0.3634 - acc: 0.5381 - auc: 0.5531 - f1: 0.5381 - val_loss: 0.3440 - val_acc: 0.6667 - val_auc: 0.7311 - val_f1: 0.6667\n",
      "Epoch 2/20\n",
      "853/853 [==============================] - 0s 89us/step - loss: 0.3213 - acc: 0.6741 - auc: 0.7359 - f1: 0.6741 - val_loss: 0.3590 - val_acc: 0.6667 - val_auc: 0.7290 - val_f1: 0.6667\n",
      "Epoch 3/20\n",
      "853/853 [==============================] - 0s 90us/step - loss: 0.3068 - acc: 0.6753 - auc: 0.7582 - f1: 0.6753 - val_loss: 0.3337 - val_acc: 0.6714 - val_auc: 0.7259 - val_f1: 0.6714\n",
      "Epoch 4/20\n",
      "853/853 [==============================] - 0s 92us/step - loss: 0.2925 - acc: 0.7069 - auc: 0.7716 - f1: 0.7069 - val_loss: 0.3263 - val_acc: 0.6854 - val_auc: 0.7162 - val_f1: 0.6854\n",
      "Epoch 5/20\n",
      "853/853 [==============================] - 0s 90us/step - loss: 0.2905 - acc: 0.6975 - auc: 0.7664 - f1: 0.6975 - val_loss: 0.3216 - val_acc: 0.6573 - val_auc: 0.6996 - val_f1: 0.6573\n",
      "Epoch 6/20\n",
      "853/853 [==============================] - 0s 92us/step - loss: 0.2831 - acc: 0.7069 - auc: 0.7812 - f1: 0.7069 - val_loss: 0.3231 - val_acc: 0.6479 - val_auc: 0.7032 - val_f1: 0.6479\n",
      "Epoch 7/20\n",
      "853/853 [==============================] - 0s 98us/step - loss: 0.2807 - acc: 0.7057 - auc: 0.7814 - f1: 0.7057 - val_loss: 0.3258 - val_acc: 0.6714 - val_auc: 0.7193 - val_f1: 0.6714\n",
      "Epoch 8/20\n",
      "853/853 [==============================] - 0s 94us/step - loss: 0.2739 - acc: 0.7222 - auc: 0.7943 - f1: 0.7222 - val_loss: 0.3329 - val_acc: 0.6808 - val_auc: 0.7281 - val_f1: 0.6808\n",
      "Epoch 9/20\n",
      "853/853 [==============================] - 0s 97us/step - loss: 0.2701 - acc: 0.7046 - auc: 0.7989 - f1: 0.7046 - val_loss: 0.3358 - val_acc: 0.6761 - val_auc: 0.7302 - val_f1: 0.6761\n",
      "Epoch 10/20\n",
      "853/853 [==============================] - 0s 96us/step - loss: 0.2595 - acc: 0.7245 - auc: 0.8170 - f1: 0.7245 - val_loss: 0.3354 - val_acc: 0.6761 - val_auc: 0.7301 - val_f1: 0.6761\n",
      "Epoch 11/20\n",
      "853/853 [==============================] - 0s 97us/step - loss: 0.2702 - acc: 0.7245 - auc: 0.8017 - f1: 0.7245 - val_loss: 0.3313 - val_acc: 0.6667 - val_auc: 0.7298 - val_f1: 0.6667\n",
      "Epoch 12/20\n",
      "853/853 [==============================] - 0s 100us/step - loss: 0.2564 - acc: 0.7444 - auc: 0.8217 - f1: 0.7444 - val_loss: 0.3269 - val_acc: 0.6761 - val_auc: 0.7254 - val_f1: 0.6761\n",
      "Epoch 13/20\n",
      "853/853 [==============================] - 0s 99us/step - loss: 0.2625 - acc: 0.7362 - auc: 0.8124 - f1: 0.7362 - val_loss: 0.3241 - val_acc: 0.6761 - val_auc: 0.7230 - val_f1: 0.6761\n",
      "Epoch 14/20\n",
      "853/853 [==============================] - 0s 102us/step - loss: 0.2576 - acc: 0.7386 - auc: 0.8204 - f1: 0.7386 - val_loss: 0.3226 - val_acc: 0.6854 - val_auc: 0.7237 - val_f1: 0.6854\n",
      "Epoch 15/20\n",
      "853/853 [==============================] - 0s 101us/step - loss: 0.2483 - acc: 0.7515 - auc: 0.8352 - f1: 0.7515 - val_loss: 0.3247 - val_acc: 0.6667 - val_auc: 0.7320 - val_f1: 0.6667\n",
      "Epoch 16/20\n",
      "853/853 [==============================] - 0s 101us/step - loss: 0.2506 - acc: 0.7608 - auc: 0.8306 - f1: 0.7608 - val_loss: 0.3290 - val_acc: 0.6808 - val_auc: 0.7369 - val_f1: 0.6808\n",
      "Epoch 17/20\n",
      "853/853 [==============================] - 0s 99us/step - loss: 0.2440 - acc: 0.7667 - auc: 0.8442 - f1: 0.7667 - val_loss: 0.3341 - val_acc: 0.6714 - val_auc: 0.7403 - val_f1: 0.6714\n",
      "Epoch 18/20\n",
      "853/853 [==============================] - 0s 101us/step - loss: 0.2511 - acc: 0.7444 - auc: 0.8339 - f1: 0.7444 - val_loss: 0.3338 - val_acc: 0.6854 - val_auc: 0.7394 - val_f1: 0.6854\n",
      "Epoch 19/20\n",
      "853/853 [==============================] - 0s 102us/step - loss: 0.2388 - acc: 0.7667 - auc: 0.8493 - f1: 0.7667 - val_loss: 0.3286 - val_acc: 0.6714 - val_auc: 0.7413 - val_f1: 0.6714\n",
      "Epoch 20/20\n",
      "853/853 [==============================] - 0s 101us/step - loss: 0.2382 - acc: 0.7773 - auc: 0.8513 - f1: 0.7773 - val_loss: 0.3292 - val_acc: 0.6995 - val_auc: 0.7408 - val_f1: 0.6995\n",
      "[[85 27]\n",
      " [37 64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73       112\n",
      "           1       0.70      0.63      0.67       101\n",
      "\n",
      "    accuracy                           0.70       213\n",
      "   macro avg       0.70      0.70      0.70       213\n",
      "weighted avg       0.70      0.70      0.70       213\n",
      "\n",
      "Training on fold 5/5...\n",
      "model dim:  (5, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_58 (GRU)                 (None, 5, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 5, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_59 (GRU)                 (None, 5, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 5, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_60 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 854 samples, validate on 212 samples\n",
      "Epoch 1/20\n",
      "854/854 [==============================] - 5s 6ms/step - loss: 0.3654 - acc: 0.5574 - auc: 0.6047 - f1: 0.5574 - val_loss: 0.3018 - val_acc: 0.6462 - val_auc: 0.7433 - val_f1: 0.6462\n",
      "Epoch 2/20\n",
      "854/854 [==============================] - 0s 89us/step - loss: 0.3098 - acc: 0.6827 - auc: 0.7404 - f1: 0.6827 - val_loss: 0.3198 - val_acc: 0.6179 - val_auc: 0.7559 - val_f1: 0.6179\n",
      "Epoch 3/20\n",
      "854/854 [==============================] - 0s 92us/step - loss: 0.3100 - acc: 0.6663 - auc: 0.7529 - f1: 0.6663 - val_loss: 0.2991 - val_acc: 0.6698 - val_auc: 0.7582 - val_f1: 0.6698\n",
      "Epoch 4/20\n",
      "854/854 [==============================] - 0s 94us/step - loss: 0.2986 - acc: 0.7002 - auc: 0.7563 - f1: 0.7002 - val_loss: 0.2993 - val_acc: 0.6840 - val_auc: 0.7573 - val_f1: 0.6840\n",
      "Epoch 5/20\n",
      "854/854 [==============================] - 0s 96us/step - loss: 0.2954 - acc: 0.6967 - auc: 0.7568 - f1: 0.6967 - val_loss: 0.2884 - val_acc: 0.7264 - val_auc: 0.7654 - val_f1: 0.7264\n",
      "Epoch 6/20\n",
      "854/854 [==============================] - 0s 94us/step - loss: 0.2907 - acc: 0.7084 - auc: 0.7626 - f1: 0.7084 - val_loss: 0.2835 - val_acc: 0.7358 - val_auc: 0.7861 - val_f1: 0.7358\n",
      "Epoch 7/20\n",
      "854/854 [==============================] - 0s 91us/step - loss: 0.2893 - acc: 0.6909 - auc: 0.7686 - f1: 0.6909 - val_loss: 0.2729 - val_acc: 0.7500 - val_auc: 0.7971 - val_f1: 0.7500\n",
      "Epoch 8/20\n",
      "854/854 [==============================] - 0s 91us/step - loss: 0.2860 - acc: 0.6979 - auc: 0.7721 - f1: 0.6979 - val_loss: 0.2693 - val_acc: 0.7264 - val_auc: 0.8019 - val_f1: 0.7264\n",
      "Epoch 9/20\n",
      "854/854 [==============================] - 0s 96us/step - loss: 0.2762 - acc: 0.7213 - auc: 0.7922 - f1: 0.7213 - val_loss: 0.2669 - val_acc: 0.7311 - val_auc: 0.8049 - val_f1: 0.7311\n",
      "Epoch 10/20\n",
      "854/854 [==============================] - 0s 95us/step - loss: 0.2785 - acc: 0.7190 - auc: 0.7851 - f1: 0.7190 - val_loss: 0.2647 - val_acc: 0.7406 - val_auc: 0.8079 - val_f1: 0.7406\n",
      "Epoch 11/20\n",
      "854/854 [==============================] - 0s 97us/step - loss: 0.2678 - acc: 0.7213 - auc: 0.8032 - f1: 0.7213 - val_loss: 0.2698 - val_acc: 0.7406 - val_auc: 0.8057 - val_f1: 0.7406\n",
      "Epoch 12/20\n",
      "854/854 [==============================] - 0s 96us/step - loss: 0.2714 - acc: 0.7225 - auc: 0.7988 - f1: 0.7225 - val_loss: 0.2718 - val_acc: 0.7264 - val_auc: 0.7995 - val_f1: 0.7264\n",
      "Epoch 13/20\n",
      "854/854 [==============================] - 0s 98us/step - loss: 0.2712 - acc: 0.7260 - auc: 0.7995 - f1: 0.7260 - val_loss: 0.2776 - val_acc: 0.7217 - val_auc: 0.7871 - val_f1: 0.7217\n",
      "Epoch 14/20\n",
      "854/854 [==============================] - 0s 98us/step - loss: 0.2675 - acc: 0.7131 - auc: 0.8061 - f1: 0.7131 - val_loss: 0.2765 - val_acc: 0.7264 - val_auc: 0.7899 - val_f1: 0.7264\n",
      "Epoch 15/20\n",
      "854/854 [==============================] - 0s 100us/step - loss: 0.2605 - acc: 0.7155 - auc: 0.8154 - f1: 0.7155 - val_loss: 0.2726 - val_acc: 0.7311 - val_auc: 0.8004 - val_f1: 0.7311\n",
      "Epoch 16/20\n",
      "854/854 [==============================] - 0s 100us/step - loss: 0.2604 - acc: 0.7354 - auc: 0.8174 - f1: 0.7354 - val_loss: 0.2652 - val_acc: 0.7075 - val_auc: 0.8074 - val_f1: 0.7075\n",
      "Epoch 17/20\n",
      "854/854 [==============================] - 0s 99us/step - loss: 0.2554 - acc: 0.7459 - auc: 0.8245 - f1: 0.7459 - val_loss: 0.2623 - val_acc: 0.7264 - val_auc: 0.8115 - val_f1: 0.7264\n",
      "Epoch 18/20\n",
      "854/854 [==============================] - 0s 97us/step - loss: 0.2603 - acc: 0.7389 - auc: 0.8178 - f1: 0.7389 - val_loss: 0.2618 - val_acc: 0.7406 - val_auc: 0.8104 - val_f1: 0.7406\n",
      "Epoch 19/20\n",
      "854/854 [==============================] - 0s 97us/step - loss: 0.2557 - acc: 0.7342 - auc: 0.8234 - f1: 0.7342 - val_loss: 0.2613 - val_acc: 0.7170 - val_auc: 0.8131 - val_f1: 0.7170\n",
      "Epoch 20/20\n",
      "854/854 [==============================] - 0s 104us/step - loss: 0.2475 - acc: 0.7459 - auc: 0.8352 - f1: 0.7459 - val_loss: 0.2627 - val_acc: 0.7028 - val_auc: 0.8132 - val_f1: 0.7028\n",
      "[[76 36]\n",
      " [27 73]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71       112\n",
      "           1       0.67      0.73      0.70       100\n",
      "\n",
      "    accuracy                           0.70       212\n",
      "   macro avg       0.70      0.70      0.70       212\n",
      "weighted avg       0.71      0.70      0.70       212\n",
      "\n",
      "time (in seconds) 44.32639741897583\n",
      "... DONE!\n",
      "... DONE!\n",
      "window_size: 6\n",
      "generating tensor...\n",
      "...DONE!\n",
      "tensor dimensions:\n",
      "tensor input X: (932, 8, 6)\n",
      "tensor input y: (932, 2)\n",
      "proportion of y labels: (array([0, 1]), array([473, 459]))\n",
      "Splitting dataset into Train and Test sets...\n",
      "Tensor X train: (652, 6, 8)\n",
      "Tensor y train: (652, 2)\n",
      "Tensor X test: (280, 6, 8)\n",
      "Tensor y test: (280, 2)\n",
      "computing weights...\n",
      "... DONE!\n",
      "setting stratified k-fold...\n",
      "number of k: 5\n",
      "... DONE!\n",
      "Executing algorithm...\n",
      "number of epochs: 20\n",
      "number of batch: 512\n",
      "Training on fold 1/5...\n",
      "model dim:  (6, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_61 (GRU)                 (None, 6, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_62 (GRU)                 (None, 6, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_63 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 521 samples, validate on 131 samples\n",
      "Epoch 1/20\n",
      "521/521 [==============================] - 5s 10ms/step - loss: 0.3711 - acc: 0.5163 - auc: 0.5317 - f1: 0.5163 - val_loss: 0.3359 - val_acc: 0.6947 - val_auc: 0.8182 - val_f1: 0.6947\n",
      "Epoch 2/20\n",
      "521/521 [==============================] - 0s 122us/step - loss: 0.3951 - acc: 0.6008 - auc: 0.7049 - f1: 0.6008 - val_loss: 0.2738 - val_acc: 0.7252 - val_auc: 0.8214 - val_f1: 0.7252\n",
      "Epoch 3/20\n",
      "521/521 [==============================] - 0s 118us/step - loss: 0.3352 - acc: 0.6622 - auc: 0.7316 - f1: 0.6622 - val_loss: 0.3053 - val_acc: 0.7176 - val_auc: 0.8263 - val_f1: 0.7176\n",
      "Epoch 4/20\n",
      "521/521 [==============================] - 0s 119us/step - loss: 0.3664 - acc: 0.6488 - auc: 0.7261 - f1: 0.6488 - val_loss: 0.2790 - val_acc: 0.7328 - val_auc: 0.8312 - val_f1: 0.7328\n",
      "Epoch 5/20\n",
      "521/521 [==============================] - 0s 119us/step - loss: 0.3373 - acc: 0.6641 - auc: 0.7409 - f1: 0.6641 - val_loss: 0.2570 - val_acc: 0.7481 - val_auc: 0.8324 - val_f1: 0.7481\n",
      "Epoch 6/20\n",
      "521/521 [==============================] - 0s 124us/step - loss: 0.3384 - acc: 0.6660 - auc: 0.7124 - f1: 0.6660 - val_loss: 0.2649 - val_acc: 0.7328 - val_auc: 0.8268 - val_f1: 0.7328\n",
      "Epoch 7/20\n",
      "521/521 [==============================] - 0s 124us/step - loss: 0.3215 - acc: 0.6603 - auc: 0.7255 - f1: 0.6603 - val_loss: 0.3185 - val_acc: 0.6565 - val_auc: 0.8131 - val_f1: 0.6565\n",
      "Epoch 8/20\n",
      "521/521 [==============================] - 0s 127us/step - loss: 0.3527 - acc: 0.6084 - auc: 0.7153 - f1: 0.6084 - val_loss: 0.3096 - val_acc: 0.6565 - val_auc: 0.8002 - val_f1: 0.6565\n",
      "Epoch 9/20\n",
      "521/521 [==============================] - 0s 128us/step - loss: 0.3557 - acc: 0.5893 - auc: 0.6765 - f1: 0.5893 - val_loss: 0.2831 - val_acc: 0.7481 - val_auc: 0.7923 - val_f1: 0.7481\n",
      "Epoch 10/20\n",
      "521/521 [==============================] - 0s 125us/step - loss: 0.3275 - acc: 0.6315 - auc: 0.6771 - f1: 0.6315 - val_loss: 0.3125 - val_acc: 0.6718 - val_auc: 0.7904 - val_f1: 0.6718\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521/521 [==============================] - 0s 129us/step - loss: 0.3371 - acc: 0.6353 - auc: 0.7126 - f1: 0.6353 - val_loss: 0.3211 - val_acc: 0.6489 - val_auc: 0.8019 - val_f1: 0.6489\n",
      "Epoch 12/20\n",
      "521/521 [==============================] - 0s 132us/step - loss: 0.3665 - acc: 0.6161 - auc: 0.6647 - f1: 0.6161 - val_loss: 0.2835 - val_acc: 0.7023 - val_auc: 0.8336 - val_f1: 0.7023\n",
      "Epoch 13/20\n",
      "521/521 [==============================] - 0s 132us/step - loss: 0.3329 - acc: 0.6276 - auc: 0.6968 - f1: 0.6276 - val_loss: 0.2586 - val_acc: 0.7405 - val_auc: 0.8378 - val_f1: 0.7405\n",
      "Epoch 14/20\n",
      "521/521 [==============================] - 0s 134us/step - loss: 0.3208 - acc: 0.6488 - auc: 0.7006 - f1: 0.6488 - val_loss: 0.2498 - val_acc: 0.7405 - val_auc: 0.8427 - val_f1: 0.7405\n",
      "Epoch 15/20\n",
      "521/521 [==============================] - 0s 130us/step - loss: 0.3104 - acc: 0.6603 - auc: 0.7253 - f1: 0.6603 - val_loss: 0.2562 - val_acc: 0.7710 - val_auc: 0.8424 - val_f1: 0.7710\n",
      "Epoch 16/20\n",
      "521/521 [==============================] - 0s 125us/step - loss: 0.3115 - acc: 0.6564 - auc: 0.7333 - f1: 0.6564 - val_loss: 0.2665 - val_acc: 0.7328 - val_auc: 0.8497 - val_f1: 0.7328\n",
      "Epoch 17/20\n",
      "521/521 [==============================] - 0s 134us/step - loss: 0.3255 - acc: 0.6468 - auc: 0.7230 - f1: 0.6468 - val_loss: 0.2620 - val_acc: 0.7405 - val_auc: 0.8487 - val_f1: 0.7405\n",
      "Epoch 18/20\n",
      "521/521 [==============================] - 0s 129us/step - loss: 0.3176 - acc: 0.6564 - auc: 0.7319 - f1: 0.6564 - val_loss: 0.2449 - val_acc: 0.7863 - val_auc: 0.8466 - val_f1: 0.7863\n",
      "Epoch 19/20\n",
      "521/521 [==============================] - 0s 133us/step - loss: 0.3118 - acc: 0.6583 - auc: 0.7159 - f1: 0.6583 - val_loss: 0.2436 - val_acc: 0.7481 - val_auc: 0.8480 - val_f1: 0.7481\n",
      "Epoch 20/20\n",
      "521/521 [==============================] - 0s 142us/step - loss: 0.3003 - acc: 0.6814 - auc: 0.7474 - f1: 0.6814 - val_loss: 0.2442 - val_acc: 0.7939 - val_auc: 0.8452 - val_f1: 0.7939\n",
      "[[49 16]\n",
      " [11 55]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.78        65\n",
      "           1       0.77      0.83      0.80        66\n",
      "\n",
      "    accuracy                           0.79       131\n",
      "   macro avg       0.80      0.79      0.79       131\n",
      "weighted avg       0.80      0.79      0.79       131\n",
      "\n",
      "Training on fold 2/5...\n",
      "model dim:  (6, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_64 (GRU)                 (None, 6, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_65 (GRU)                 (None, 6, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_66 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 521 samples, validate on 131 samples\n",
      "Epoch 1/20\n",
      "521/521 [==============================] - 5s 10ms/step - loss: 0.3593 - acc: 0.5451 - auc: 0.5656 - f1: 0.5451 - val_loss: 0.3050 - val_acc: 0.6641 - val_auc: 0.7564 - val_f1: 0.6641\n",
      "Epoch 2/20\n",
      "521/521 [==============================] - 0s 122us/step - loss: 0.3059 - acc: 0.6507 - auc: 0.7376 - f1: 0.6507 - val_loss: 0.3161 - val_acc: 0.6794 - val_auc: 0.7688 - val_f1: 0.6794\n",
      "Epoch 3/20\n",
      "521/521 [==============================] - 0s 124us/step - loss: 0.3291 - acc: 0.6564 - auc: 0.7242 - f1: 0.6564 - val_loss: 0.3034 - val_acc: 0.7252 - val_auc: 0.7706 - val_f1: 0.7252\n",
      "Epoch 4/20\n",
      "521/521 [==============================] - 0s 119us/step - loss: 0.3172 - acc: 0.6852 - auc: 0.7433 - f1: 0.6852 - val_loss: 0.3105 - val_acc: 0.7023 - val_auc: 0.7751 - val_f1: 0.7023\n",
      "Epoch 5/20\n",
      "521/521 [==============================] - 0s 124us/step - loss: 0.3218 - acc: 0.6756 - auc: 0.7583 - f1: 0.6756 - val_loss: 0.3116 - val_acc: 0.7252 - val_auc: 0.7802 - val_f1: 0.7252\n",
      "Epoch 6/20\n",
      "521/521 [==============================] - 0s 127us/step - loss: 0.3269 - acc: 0.6756 - auc: 0.7503 - f1: 0.6756 - val_loss: 0.2943 - val_acc: 0.7023 - val_auc: 0.7851 - val_f1: 0.7023\n",
      "Epoch 7/20\n",
      "521/521 [==============================] - 0s 125us/step - loss: 0.3176 - acc: 0.6660 - auc: 0.7476 - f1: 0.6660 - val_loss: 0.2829 - val_acc: 0.7099 - val_auc: 0.7811 - val_f1: 0.7099\n",
      "Epoch 8/20\n",
      "521/521 [==============================] - 0s 125us/step - loss: 0.3065 - acc: 0.6929 - auc: 0.7376 - f1: 0.6929 - val_loss: 0.2938 - val_acc: 0.6565 - val_auc: 0.7597 - val_f1: 0.6565\n",
      "Epoch 9/20\n",
      "521/521 [==============================] - 0s 123us/step - loss: 0.3075 - acc: 0.6891 - auc: 0.7296 - f1: 0.6891 - val_loss: 0.3079 - val_acc: 0.6565 - val_auc: 0.7319 - val_f1: 0.6565\n",
      "Epoch 10/20\n",
      "521/521 [==============================] - 0s 137us/step - loss: 0.3099 - acc: 0.6660 - auc: 0.7299 - f1: 0.6660 - val_loss: 0.3043 - val_acc: 0.6794 - val_auc: 0.7345 - val_f1: 0.6794\n",
      "Epoch 11/20\n",
      "521/521 [==============================] - 0s 130us/step - loss: 0.3071 - acc: 0.6987 - auc: 0.7287 - f1: 0.6987 - val_loss: 0.2968 - val_acc: 0.6794 - val_auc: 0.7441 - val_f1: 0.6794\n",
      "Epoch 12/20\n",
      "521/521 [==============================] - 0s 132us/step - loss: 0.3075 - acc: 0.6603 - auc: 0.7233 - f1: 0.6603 - val_loss: 0.2923 - val_acc: 0.6947 - val_auc: 0.7515 - val_f1: 0.6947\n",
      "Epoch 13/20\n",
      "521/521 [==============================] - 0s 133us/step - loss: 0.2963 - acc: 0.6987 - auc: 0.7525 - f1: 0.6987 - val_loss: 0.2920 - val_acc: 0.7023 - val_auc: 0.7639 - val_f1: 0.7023\n",
      "Epoch 14/20\n",
      "521/521 [==============================] - 0s 133us/step - loss: 0.3003 - acc: 0.6871 - auc: 0.7423 - f1: 0.6871 - val_loss: 0.2938 - val_acc: 0.6718 - val_auc: 0.7727 - val_f1: 0.6718\n",
      "Epoch 15/20\n",
      "521/521 [==============================] - 0s 141us/step - loss: 0.2883 - acc: 0.6910 - auc: 0.7763 - f1: 0.6910 - val_loss: 0.3027 - val_acc: 0.6794 - val_auc: 0.7748 - val_f1: 0.6794\n",
      "Epoch 16/20\n",
      "521/521 [==============================] - 0s 135us/step - loss: 0.2970 - acc: 0.7006 - auc: 0.7734 - f1: 0.7006 - val_loss: 0.3059 - val_acc: 0.6794 - val_auc: 0.7758 - val_f1: 0.6794\n",
      "Epoch 17/20\n",
      "521/521 [==============================] - 0s 128us/step - loss: 0.2922 - acc: 0.7140 - auc: 0.7877 - f1: 0.7140 - val_loss: 0.3001 - val_acc: 0.6947 - val_auc: 0.7741 - val_f1: 0.6947\n",
      "Epoch 18/20\n",
      "521/521 [==============================] - 0s 129us/step - loss: 0.2941 - acc: 0.7083 - auc: 0.7804 - f1: 0.7083 - val_loss: 0.3000 - val_acc: 0.7023 - val_auc: 0.7716 - val_f1: 0.7023\n",
      "Epoch 19/20\n",
      "521/521 [==============================] - 0s 129us/step - loss: 0.2917 - acc: 0.6987 - auc: 0.7818 - f1: 0.6987 - val_loss: 0.3030 - val_acc: 0.7099 - val_auc: 0.7695 - val_f1: 0.7099\n",
      "Epoch 20/20\n",
      "521/521 [==============================] - 0s 135us/step - loss: 0.2919 - acc: 0.7217 - auc: 0.7789 - f1: 0.7217 - val_loss: 0.3032 - val_acc: 0.7023 - val_auc: 0.7655 - val_f1: 0.7023\n",
      "[[43 22]\n",
      " [17 49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.66      0.69        65\n",
      "           1       0.69      0.74      0.72        66\n",
      "\n",
      "    accuracy                           0.70       131\n",
      "   macro avg       0.70      0.70      0.70       131\n",
      "weighted avg       0.70      0.70      0.70       131\n",
      "\n",
      "Training on fold 3/5...\n",
      "model dim:  (6, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_67 (GRU)                 (None, 6, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_68 (GRU)                 (None, 6, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_69 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 522 samples, validate on 130 samples\n",
      "Epoch 1/20\n",
      "522/522 [==============================] - 6s 11ms/step - loss: 0.3587 - acc: 0.5690 - auc: 0.5868 - f1: 0.5690 - val_loss: 0.3544 - val_acc: 0.6231 - val_auc: 0.6937 - val_f1: 0.6231\n",
      "Epoch 2/20\n",
      "522/522 [==============================] - 0s 124us/step - loss: 0.3387 - acc: 0.6456 - auc: 0.7172 - f1: 0.6456 - val_loss: 0.4030 - val_acc: 0.6077 - val_auc: 0.6975 - val_f1: 0.6077\n",
      "Epoch 3/20\n",
      "522/522 [==============================] - 0s 119us/step - loss: 0.3245 - acc: 0.6686 - auc: 0.7520 - f1: 0.6686 - val_loss: 0.3756 - val_acc: 0.6462 - val_auc: 0.6914 - val_f1: 0.6462\n",
      "Epoch 4/20\n",
      "522/522 [==============================] - 0s 118us/step - loss: 0.3106 - acc: 0.6762 - auc: 0.7568 - f1: 0.6762 - val_loss: 0.3349 - val_acc: 0.6000 - val_auc: 0.6772 - val_f1: 0.6000\n",
      "Epoch 5/20\n",
      "522/522 [==============================] - 0s 123us/step - loss: 0.3007 - acc: 0.6590 - auc: 0.7488 - f1: 0.6590 - val_loss: 0.3415 - val_acc: 0.6231 - val_auc: 0.6637 - val_f1: 0.6231\n",
      "Epoch 6/20\n",
      "522/522 [==============================] - 0s 128us/step - loss: 0.2915 - acc: 0.6897 - auc: 0.7804 - f1: 0.6897 - val_loss: 0.3462 - val_acc: 0.6000 - val_auc: 0.6428 - val_f1: 0.6000\n",
      "Epoch 7/20\n",
      "522/522 [==============================] - 0s 132us/step - loss: 0.3166 - acc: 0.6360 - auc: 0.7204 - f1: 0.6360 - val_loss: 0.3462 - val_acc: 0.5923 - val_auc: 0.6402 - val_f1: 0.5923\n",
      "Epoch 8/20\n",
      "522/522 [==============================] - 0s 123us/step - loss: 0.3014 - acc: 0.6877 - auc: 0.7389 - f1: 0.6877 - val_loss: 0.3727 - val_acc: 0.5846 - val_auc: 0.6592 - val_f1: 0.5846\n",
      "Epoch 9/20\n",
      "522/522 [==============================] - 0s 129us/step - loss: 0.3032 - acc: 0.6992 - auc: 0.7594 - f1: 0.6992 - val_loss: 0.3830 - val_acc: 0.5846 - val_auc: 0.6729 - val_f1: 0.5846\n",
      "Epoch 10/20\n",
      "522/522 [==============================] - 0s 127us/step - loss: 0.3077 - acc: 0.6858 - auc: 0.7678 - f1: 0.6858 - val_loss: 0.3539 - val_acc: 0.6000 - val_auc: 0.6788 - val_f1: 0.6000\n",
      "Epoch 11/20\n",
      "522/522 [==============================] - 0s 128us/step - loss: 0.2814 - acc: 0.7107 - auc: 0.7844 - f1: 0.7107 - val_loss: 0.3528 - val_acc: 0.6385 - val_auc: 0.6772 - val_f1: 0.6385\n",
      "Epoch 12/20\n",
      "522/522 [==============================] - 0s 136us/step - loss: 0.3020 - acc: 0.6820 - auc: 0.7696 - f1: 0.6820 - val_loss: 0.3608 - val_acc: 0.6385 - val_auc: 0.6755 - val_f1: 0.6385\n",
      "Epoch 13/20\n",
      "522/522 [==============================] - 0s 124us/step - loss: 0.3159 - acc: 0.6916 - auc: 0.7652 - f1: 0.6916 - val_loss: 0.3533 - val_acc: 0.6308 - val_auc: 0.6762 - val_f1: 0.6308\n",
      "Epoch 14/20\n",
      "522/522 [==============================] - 0s 131us/step - loss: 0.3085 - acc: 0.6762 - auc: 0.7591 - f1: 0.6762 - val_loss: 0.3414 - val_acc: 0.6385 - val_auc: 0.6772 - val_f1: 0.6385\n",
      "Epoch 15/20\n",
      "522/522 [==============================] - 0s 128us/step - loss: 0.2989 - acc: 0.6724 - auc: 0.7578 - f1: 0.6724 - val_loss: 0.3482 - val_acc: 0.5846 - val_auc: 0.6776 - val_f1: 0.5846\n",
      "Epoch 16/20\n",
      "522/522 [==============================] - 0s 134us/step - loss: 0.2902 - acc: 0.7031 - auc: 0.7694 - f1: 0.7031 - val_loss: 0.3768 - val_acc: 0.6462 - val_auc: 0.6755 - val_f1: 0.6462\n",
      "Epoch 17/20\n",
      "522/522 [==============================] - 0s 130us/step - loss: 0.3161 - acc: 0.6686 - auc: 0.7516 - f1: 0.6686 - val_loss: 0.3793 - val_acc: 0.6077 - val_auc: 0.6738 - val_f1: 0.6077\n",
      "Epoch 18/20\n",
      "522/522 [==============================] - 0s 137us/step - loss: 0.3030 - acc: 0.7069 - auc: 0.7692 - f1: 0.7069 - val_loss: 0.3637 - val_acc: 0.6077 - val_auc: 0.6760 - val_f1: 0.6077\n",
      "Epoch 19/20\n",
      "522/522 [==============================] - 0s 137us/step - loss: 0.2704 - acc: 0.7395 - auc: 0.8058 - f1: 0.7395 - val_loss: 0.3606 - val_acc: 0.6231 - val_auc: 0.6760 - val_f1: 0.6231\n",
      "Epoch 20/20\n",
      "522/522 [==============================] - 0s 133us/step - loss: 0.2790 - acc: 0.7165 - auc: 0.7872 - f1: 0.7165 - val_loss: 0.3664 - val_acc: 0.6308 - val_auc: 0.6760 - val_f1: 0.6308\n",
      "[[47 18]\n",
      " [30 35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.72      0.66        65\n",
      "           1       0.66      0.54      0.59        65\n",
      "\n",
      "    accuracy                           0.63       130\n",
      "   macro avg       0.64      0.63      0.63       130\n",
      "weighted avg       0.64      0.63      0.63       130\n",
      "\n",
      "Training on fold 4/5...\n",
      "model dim:  (6, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_70 (GRU)                 (None, 6, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_71 (GRU)                 (None, 6, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_72 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 522 samples, validate on 130 samples\n",
      "Epoch 1/20\n",
      "522/522 [==============================] - 6s 11ms/step - loss: 0.4339 - acc: 0.5038 - auc: 0.5532 - f1: 0.5038 - val_loss: 0.3464 - val_acc: 0.6000 - val_auc: 0.7053 - val_f1: 0.6000\n",
      "Epoch 2/20\n",
      "522/522 [==============================] - 0s 118us/step - loss: 0.3533 - acc: 0.5920 - auc: 0.6488 - f1: 0.5920 - val_loss: 0.3087 - val_acc: 0.6692 - val_auc: 0.7382 - val_f1: 0.6692\n",
      "Epoch 3/20\n",
      "522/522 [==============================] - 0s 117us/step - loss: 0.3128 - acc: 0.6686 - auc: 0.7211 - f1: 0.6686 - val_loss: 0.3068 - val_acc: 0.6923 - val_auc: 0.7489 - val_f1: 0.6923\n",
      "Epoch 4/20\n",
      "522/522 [==============================] - 0s 119us/step - loss: 0.3146 - acc: 0.6628 - auc: 0.7354 - f1: 0.6628 - val_loss: 0.3013 - val_acc: 0.6692 - val_auc: 0.7538 - val_f1: 0.6692\n",
      "Epoch 5/20\n",
      "522/522 [==============================] - 0s 123us/step - loss: 0.3197 - acc: 0.6590 - auc: 0.7267 - f1: 0.6590 - val_loss: 0.2977 - val_acc: 0.6846 - val_auc: 0.7583 - val_f1: 0.6846\n",
      "Epoch 6/20\n",
      "522/522 [==============================] - 0s 126us/step - loss: 0.3143 - acc: 0.6705 - auc: 0.7362 - f1: 0.6705 - val_loss: 0.3013 - val_acc: 0.7154 - val_auc: 0.7626 - val_f1: 0.7154\n",
      "Epoch 7/20\n",
      "522/522 [==============================] - 0s 126us/step - loss: 0.3067 - acc: 0.6877 - auc: 0.7525 - f1: 0.6877 - val_loss: 0.3080 - val_acc: 0.6923 - val_auc: 0.7569 - val_f1: 0.6923\n",
      "Epoch 8/20\n",
      "522/522 [==============================] - 0s 124us/step - loss: 0.3215 - acc: 0.6858 - auc: 0.7303 - f1: 0.6858 - val_loss: 0.3047 - val_acc: 0.6615 - val_auc: 0.7456 - val_f1: 0.6615\n",
      "Epoch 9/20\n",
      "522/522 [==============================] - 0s 128us/step - loss: 0.3109 - acc: 0.6724 - auc: 0.7417 - f1: 0.6724 - val_loss: 0.3006 - val_acc: 0.6769 - val_auc: 0.7439 - val_f1: 0.6769\n",
      "Epoch 10/20\n",
      "522/522 [==============================] - 0s 130us/step - loss: 0.3102 - acc: 0.6762 - auc: 0.7286 - f1: 0.6762 - val_loss: 0.3004 - val_acc: 0.6769 - val_auc: 0.7567 - val_f1: 0.6769\n",
      "Epoch 11/20\n",
      "522/522 [==============================] - 0s 129us/step - loss: 0.3021 - acc: 0.6858 - auc: 0.7515 - f1: 0.6858 - val_loss: 0.2992 - val_acc: 0.6692 - val_auc: 0.7652 - val_f1: 0.6692\n",
      "Epoch 12/20\n",
      "522/522 [==============================] - 0s 133us/step - loss: 0.3025 - acc: 0.6820 - auc: 0.7524 - f1: 0.6820 - val_loss: 0.2915 - val_acc: 0.6385 - val_auc: 0.7721 - val_f1: 0.6385\n",
      "Epoch 13/20\n",
      "522/522 [==============================] - 0s 128us/step - loss: 0.2981 - acc: 0.6973 - auc: 0.7578 - f1: 0.6973 - val_loss: 0.2871 - val_acc: 0.7154 - val_auc: 0.7730 - val_f1: 0.7154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "522/522 [==============================] - 0s 130us/step - loss: 0.2899 - acc: 0.7069 - auc: 0.7673 - f1: 0.7069 - val_loss: 0.2997 - val_acc: 0.6923 - val_auc: 0.7737 - val_f1: 0.6923\n",
      "Epoch 15/20\n",
      "522/522 [==============================] - 0s 127us/step - loss: 0.3062 - acc: 0.6839 - auc: 0.7516 - f1: 0.6839 - val_loss: 0.3005 - val_acc: 0.6923 - val_auc: 0.7785 - val_f1: 0.6923\n",
      "Epoch 16/20\n",
      "522/522 [==============================] - 0s 137us/step - loss: 0.2979 - acc: 0.6858 - auc: 0.7639 - f1: 0.6858 - val_loss: 0.2845 - val_acc: 0.7000 - val_auc: 0.7811 - val_f1: 0.7000\n",
      "Epoch 17/20\n",
      "522/522 [==============================] - 0s 132us/step - loss: 0.2966 - acc: 0.6992 - auc: 0.7546 - f1: 0.6992 - val_loss: 0.2891 - val_acc: 0.6692 - val_auc: 0.7815 - val_f1: 0.6692\n",
      "Epoch 18/20\n",
      "522/522 [==============================] - 0s 136us/step - loss: 0.3023 - acc: 0.6820 - auc: 0.7559 - f1: 0.6820 - val_loss: 0.3107 - val_acc: 0.6923 - val_auc: 0.7815 - val_f1: 0.6923\n",
      "Epoch 19/20\n",
      "522/522 [==============================] - 0s 130us/step - loss: 0.3225 - acc: 0.6552 - auc: 0.7576 - f1: 0.6552 - val_loss: 0.3179 - val_acc: 0.6692 - val_auc: 0.7830 - val_f1: 0.6692\n",
      "Epoch 20/20\n",
      "522/522 [==============================] - 0s 137us/step - loss: 0.3198 - acc: 0.6686 - auc: 0.7717 - f1: 0.6686 - val_loss: 0.2939 - val_acc: 0.6538 - val_auc: 0.7844 - val_f1: 0.6538\n",
      "[[52 13]\n",
      " [32 33]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.80      0.70        65\n",
      "           1       0.72      0.51      0.59        65\n",
      "\n",
      "    accuracy                           0.65       130\n",
      "   macro avg       0.67      0.65      0.65       130\n",
      "weighted avg       0.67      0.65      0.65       130\n",
      "\n",
      "Training on fold 5/5...\n",
      "model dim:  (6, 8) 2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_73 (GRU)                 (None, 6, 256)            203520    \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "gru_74 (GRU)                 (None, 6, 128)            147840    \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "gru_75 (GRU)                 (None, 64)                37056     \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 388,546\n",
      "Trainable params: 388,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 522 samples, validate on 130 samples\n",
      "Epoch 1/20\n",
      "522/522 [==============================] - 6s 12ms/step - loss: 0.3628 - acc: 0.5383 - auc: 0.5899 - f1: 0.5383 - val_loss: 0.3523 - val_acc: 0.6154 - val_auc: 0.6528 - val_f1: 0.6154\n",
      "Epoch 2/20\n",
      "522/522 [==============================] - 0s 118us/step - loss: 0.3126 - acc: 0.6705 - auc: 0.7400 - f1: 0.6705 - val_loss: 0.3695 - val_acc: 0.5615 - val_auc: 0.6663 - val_f1: 0.5615\n",
      "Epoch 3/20\n",
      "522/522 [==============================] - 0s 122us/step - loss: 0.3125 - acc: 0.6724 - auc: 0.7529 - f1: 0.6724 - val_loss: 0.3795 - val_acc: 0.5692 - val_auc: 0.6743 - val_f1: 0.5692\n",
      "Epoch 4/20\n",
      "522/522 [==============================] - 0s 125us/step - loss: 0.3191 - acc: 0.6628 - auc: 0.7570 - f1: 0.6628 - val_loss: 0.3604 - val_acc: 0.6154 - val_auc: 0.6854 - val_f1: 0.6154\n",
      "Epoch 5/20\n",
      "522/522 [==============================] - 0s 128us/step - loss: 0.3046 - acc: 0.7050 - auc: 0.7652 - f1: 0.7050 - val_loss: 0.3409 - val_acc: 0.6154 - val_auc: 0.7006 - val_f1: 0.6154\n",
      "Epoch 6/20\n",
      "522/522 [==============================] - 0s 125us/step - loss: 0.3006 - acc: 0.6877 - auc: 0.7587 - f1: 0.6877 - val_loss: 0.3271 - val_acc: 0.6154 - val_auc: 0.7025 - val_f1: 0.6154\n",
      "Epoch 7/20\n",
      "522/522 [==============================] - 0s 126us/step - loss: 0.2995 - acc: 0.6858 - auc: 0.7508 - f1: 0.6858 - val_loss: 0.3234 - val_acc: 0.6231 - val_auc: 0.6956 - val_f1: 0.6231\n",
      "Epoch 8/20\n",
      "522/522 [==============================] - 0s 131us/step - loss: 0.2950 - acc: 0.6992 - auc: 0.7609 - f1: 0.6992 - val_loss: 0.3301 - val_acc: 0.6385 - val_auc: 0.6992 - val_f1: 0.6385\n",
      "Epoch 9/20\n",
      "522/522 [==============================] - 0s 129us/step - loss: 0.2962 - acc: 0.6858 - auc: 0.7636 - f1: 0.6858 - val_loss: 0.3240 - val_acc: 0.6308 - val_auc: 0.7082 - val_f1: 0.6308\n",
      "Epoch 10/20\n",
      "522/522 [==============================] - 0s 129us/step - loss: 0.2998 - acc: 0.6839 - auc: 0.7551 - f1: 0.6839 - val_loss: 0.3096 - val_acc: 0.6231 - val_auc: 0.7243 - val_f1: 0.6231\n",
      "Epoch 11/20\n",
      "522/522 [==============================] - 0s 132us/step - loss: 0.2974 - acc: 0.6801 - auc: 0.7545 - f1: 0.6801 - val_loss: 0.3066 - val_acc: 0.6462 - val_auc: 0.7309 - val_f1: 0.6462\n",
      "Epoch 12/20\n",
      "522/522 [==============================] - 0s 128us/step - loss: 0.2910 - acc: 0.6973 - auc: 0.7656 - f1: 0.6973 - val_loss: 0.3117 - val_acc: 0.6385 - val_auc: 0.7330 - val_f1: 0.6385\n",
      "Epoch 13/20\n",
      "522/522 [==============================] - 0s 129us/step - loss: 0.2976 - acc: 0.6533 - auc: 0.7566 - f1: 0.6533 - val_loss: 0.3081 - val_acc: 0.6538 - val_auc: 0.7422 - val_f1: 0.6538\n",
      "Epoch 14/20\n",
      "522/522 [==============================] - 0s 127us/step - loss: 0.2865 - acc: 0.6877 - auc: 0.7730 - f1: 0.6877 - val_loss: 0.3063 - val_acc: 0.6615 - val_auc: 0.7458 - val_f1: 0.6615\n",
      "Epoch 15/20\n",
      "522/522 [==============================] - 0s 132us/step - loss: 0.2906 - acc: 0.7011 - auc: 0.7672 - f1: 0.7011 - val_loss: 0.3076 - val_acc: 0.6538 - val_auc: 0.7437 - val_f1: 0.6538\n",
      "Epoch 16/20\n",
      "522/522 [==============================] - 0s 131us/step - loss: 0.2865 - acc: 0.6877 - auc: 0.7725 - f1: 0.6877 - val_loss: 0.3088 - val_acc: 0.6538 - val_auc: 0.7401 - val_f1: 0.6538\n",
      "Epoch 17/20\n",
      "522/522 [==============================] - 0s 134us/step - loss: 0.2849 - acc: 0.7050 - auc: 0.7730 - f1: 0.7050 - val_loss: 0.3127 - val_acc: 0.6462 - val_auc: 0.7333 - val_f1: 0.6462\n",
      "Epoch 18/20\n",
      "522/522 [==============================] - 0s 131us/step - loss: 0.2811 - acc: 0.7050 - auc: 0.7800 - f1: 0.7050 - val_loss: 0.3162 - val_acc: 0.6462 - val_auc: 0.7290 - val_f1: 0.6462\n",
      "Epoch 19/20\n",
      "522/522 [==============================] - 0s 137us/step - loss: 0.2760 - acc: 0.7146 - auc: 0.7894 - f1: 0.7146 - val_loss: 0.3161 - val_acc: 0.6538 - val_auc: 0.7297 - val_f1: 0.6538\n",
      "Epoch 20/20\n",
      "522/522 [==============================] - 0s 136us/step - loss: 0.2782 - acc: 0.7165 - auc: 0.7849 - f1: 0.7165 - val_loss: 0.3162 - val_acc: 0.6923 - val_auc: 0.7342 - val_f1: 0.6923\n",
      "[[40 25]\n",
      " [15 50]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.62      0.67        65\n",
      "           1       0.67      0.77      0.71        65\n",
      "\n",
      "    accuracy                           0.69       130\n",
      "   macro avg       0.70      0.69      0.69       130\n",
      "weighted avg       0.70      0.69      0.69       130\n",
      "\n",
      "time (in seconds) 51.188318490982056\n",
      "... DONE!\n",
      "... DONE!\n"
     ]
    }
   ],
   "source": [
    "listResults = {} \n",
    "for i in [2, 3, 4, 5, 6]:\n",
    "    print(\"window_size: \"+str(i))\n",
    "    listResults[i] = applyTensor(i, df)\n",
    "    print(\"... DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FROM WINDOW SIZE 2\n",
      "[[620 193]\n",
      " [210 801]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75       813\n",
      "           1       0.81      0.79      0.80      1011\n",
      "\n",
      "    accuracy                           0.78      1824\n",
      "   macro avg       0.78      0.78      0.78      1824\n",
      "weighted avg       0.78      0.78      0.78      1824\n",
      "\n",
      "ROC_AUC: 0.7774462462725527\n",
      "F1-Score: 0.7807003504809432\n",
      "Precision: 0.7694497220961855\n",
      "Recall: 0.7922848664688432\n",
      "Accuracy: 0.7774462462725518\n",
      "Time in seconds: 28.81954050064087\n",
      "\n",
      "\n",
      "RESULTS FROM WINDOW SIZE 3\n",
      "[[359 192]\n",
      " [120 575]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.65      0.70       551\n",
      "           1       0.75      0.83      0.79       695\n",
      "\n",
      "    accuracy                           0.75      1246\n",
      "   macro avg       0.75      0.74      0.74      1246\n",
      "weighted avg       0.75      0.75      0.75      1246\n",
      "\n",
      "ROC_AUC: 0.739440389612082\n",
      "F1-Score: 0.7604925528978211\n",
      "Precision: 0.7036411890775353\n",
      "Recall: 0.8273381294963957\n",
      "Accuracy: 0.7394403896120854\n",
      "Time in seconds: 35.42365837097168\n",
      "\n",
      "\n",
      "RESULTS FROM WINDOW SIZE 4\n",
      "[[321  72]\n",
      " [142 260]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.82      0.75       393\n",
      "           1       0.78      0.65      0.71       402\n",
      "\n",
      "    accuracy                           0.73       795\n",
      "   macro avg       0.74      0.73      0.73       795\n",
      "weighted avg       0.74      0.73      0.73       795\n",
      "\n",
      "ROC_AUC: 0.7317800311419969\n",
      "F1-Score: 0.7068589810106838\n",
      "Precision: 0.779262377596776\n",
      "Recall: 0.6467661691542237\n",
      "Accuracy: 0.731780031142\n",
      "Time in seconds: 39.789008140563965\n",
      "\n",
      "\n",
      "RESULTS FROM WINDOW SIZE 5\n",
      "[[162  70]\n",
      " [ 56 169]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72       232\n",
      "           1       0.71      0.75      0.73       225\n",
      "\n",
      "    accuracy                           0.72       457\n",
      "   macro avg       0.73      0.72      0.72       457\n",
      "weighted avg       0.73      0.72      0.72       457\n",
      "\n",
      "ROC_AUC: 0.7246934865900383\n",
      "F1-Score: 0.7317792418671494\n",
      "Precision: 0.7134175188325627\n",
      "Recall: 0.7511111111111112\n",
      "Accuracy: 0.7246934865900385\n",
      "Time in seconds: 44.32639741897583\n",
      "\n",
      "\n",
      "RESULTS FROM WINDOW SIZE 6\n",
      "[[102  46]\n",
      " [ 36  96]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71       148\n",
      "           1       0.68      0.73      0.70       132\n",
      "\n",
      "    accuracy                           0.71       280\n",
      "   macro avg       0.71      0.71      0.71       280\n",
      "weighted avg       0.71      0.71      0.71       280\n",
      "\n",
      "ROC_AUC: 0.7082309582309577\n",
      "F1-Score: 0.7136829415310433\n",
      "Precision: 0.7005917159763325\n",
      "Recall: 0.7272727272727272\n",
      "Accuracy: 0.7082309582309583\n",
      "Time in seconds: 51.188318490982056\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [2, 3, 4, 5, 6]:\n",
    "    print(\"RESULTS FROM WINDOW SIZE\",i)\n",
    "    lastModel = listResults[i][0]\n",
    "    history_general = listResults[i][1]\n",
    "    X_test = listResults[i][2]\n",
    "    y_test = listResults[i][3]\n",
    "    time_in_seconds = listResults[i][4]\n",
    "\n",
    "    fractions_t = 1-y_test.sum(axis=0)/len(y_test)\n",
    "    weights_t = fractions_t[y_test.argmax(axis=1)]\n",
    "\n",
    "    output = lastModel.predict_classes(X_test)\n",
    "    print(confusion_matrix(y_test.argmax(axis=1), output))\n",
    "    print(classification_report(y_test.argmax(axis=1), output))\n",
    "    evaluation_metrics(y_test.argmax(axis=1), output, weights_t)\n",
    "    print(\"Time in seconds:\", time_in_seconds)\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
